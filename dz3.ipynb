{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  \n",
       "5     18.7  394.12   5.21  28.7  \n",
       "6     15.2  395.60  12.43  22.9  \n",
       "7     15.2  396.90  19.15  27.1  \n",
       "8     15.2  386.63  29.93  16.5  \n",
       "9     15.2  386.71  17.10  18.9  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "df = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "df['MEDV'] = boston_dataset.target\n",
    "df.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X = df.loc[:, df.columns != 'MEDV']\n",
    "y = df.loc[:, df.columns == 'MEDV']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline. Построение первой модели "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 128)               1792      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_output (Dense)        (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,113\n",
      "Trainable params: 10,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(13, ), activation='relu', name='dense_1'))\n",
    "model.add(Dense(64, activation='relu', name='dense_2'))\n",
    "model.add(Dense(1, activation='linear', name='dense_output'))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 573.6294 - mae: 22.1097 - val_loss: 576.2758 - val_mae: 22.1772\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 508.9468 - mae: 20.6539 - val_loss: 505.6211 - val_mae: 20.6615\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 427.4737 - mae: 18.6458 - val_loss: 409.4970 - val_mae: 18.4382\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 320.9314 - mae: 15.7588 - val_loss: 290.5051 - val_mae: 15.2499\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 203.4595 - mae: 12.1843 - val_loss: 173.1719 - val_mae: 11.1715\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 113.9534 - mae: 8.5478 - val_loss: 92.8395 - val_mae: 7.9877\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 72.8824 - mae: 6.5504 - val_loss: 57.9212 - val_mae: 6.1235\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 54.2313 - mae: 5.6996 - val_loss: 40.5069 - val_mae: 5.1382\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 40.7148 - mae: 4.8620 - val_loss: 29.8206 - val_mae: 4.3242\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 30.9572 - mae: 4.1834 - val_loss: 24.9016 - val_mae: 3.8655\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 26.6385 - mae: 3.8188 - val_loss: 21.4974 - val_mae: 3.5109\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 24.1369 - mae: 3.6404 - val_loss: 19.3072 - val_mae: 3.2819\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.6034 - mae: 3.5303 - val_loss: 18.3141 - val_mae: 3.1828\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.2216 - mae: 3.4004 - val_loss: 17.7086 - val_mae: 3.1119\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 20.2155 - mae: 3.2903 - val_loss: 17.1382 - val_mae: 3.0287\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.2914 - mae: 3.2093 - val_loss: 16.5521 - val_mae: 2.9915\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.4972 - mae: 3.1331 - val_loss: 15.9499 - val_mae: 2.9281\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.8201 - mae: 3.0748 - val_loss: 15.3712 - val_mae: 2.8662\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.2046 - mae: 3.0160 - val_loss: 14.7078 - val_mae: 2.8230\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.5386 - mae: 2.9546 - val_loss: 14.3321 - val_mae: 2.7595\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 16.0180 - mae: 2.9165 - val_loss: 13.7808 - val_mae: 2.7261\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 15.4973 - mae: 2.8693 - val_loss: 13.2151 - val_mae: 2.6420\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.0333 - mae: 2.8034 - val_loss: 12.7765 - val_mae: 2.5924\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.5969 - mae: 2.7635 - val_loss: 12.3150 - val_mae: 2.5329\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.2516 - mae: 2.7367 - val_loss: 11.8768 - val_mae: 2.5103\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.8916 - mae: 2.6859 - val_loss: 11.4530 - val_mae: 2.4600\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.6170 - mae: 2.6624 - val_loss: 11.0651 - val_mae: 2.5075\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.1658 - mae: 2.6068 - val_loss: 10.6520 - val_mae: 2.4432\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.8517 - mae: 2.5652 - val_loss: 10.2041 - val_mae: 2.3986\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.6622 - mae: 2.5395 - val_loss: 10.0747 - val_mae: 2.4352\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.2961 - mae: 2.4970 - val_loss: 9.7950 - val_mae: 2.3728\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.0541 - mae: 2.4706 - val_loss: 9.5364 - val_mae: 2.3653\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.8342 - mae: 2.4444 - val_loss: 9.2341 - val_mae: 2.3630\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.5940 - mae: 2.4358 - val_loss: 9.4693 - val_mae: 2.4356\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.3754 - mae: 2.4094 - val_loss: 9.1195 - val_mae: 2.3937\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.3653 - mae: 2.3861 - val_loss: 8.7973 - val_mae: 2.3342\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.1614 - mae: 2.3754 - val_loss: 9.2052 - val_mae: 2.4265\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.8036 - mae: 2.3472 - val_loss: 8.7802 - val_mae: 2.3491\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.6612 - mae: 2.3137 - val_loss: 8.5213 - val_mae: 2.3048\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.4919 - mae: 2.2799 - val_loss: 8.4378 - val_mae: 2.3161\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.5163 - mae: 2.2834 - val_loss: 8.0702 - val_mae: 2.2225\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.2381 - mae: 2.2637 - val_loss: 9.3060 - val_mae: 2.4057\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.1467 - mae: 2.2740 - val_loss: 8.7348 - val_mae: 2.3162\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.9801 - mae: 2.2303 - val_loss: 8.4288 - val_mae: 2.2931\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.9042 - mae: 2.2166 - val_loss: 8.7561 - val_mae: 2.3238\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.7617 - mae: 2.2373 - val_loss: 8.5227 - val_mae: 2.2939\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.6484 - mae: 2.2030 - val_loss: 8.1258 - val_mae: 2.2210\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.5520 - mae: 2.1743 - val_loss: 7.9744 - val_mae: 2.2139\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.4594 - mae: 2.1698 - val_loss: 8.1532 - val_mae: 2.2490\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3773 - mae: 2.1725 - val_loss: 9.0228 - val_mae: 2.3273\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3247 - mae: 2.1631 - val_loss: 8.2357 - val_mae: 2.2778\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3291 - mae: 2.1621 - val_loss: 8.6913 - val_mae: 2.2766\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.0763 - mae: 2.1454 - val_loss: 8.1358 - val_mae: 2.2064\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.0407 - mae: 2.1158 - val_loss: 7.9841 - val_mae: 2.1725\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.9767 - mae: 2.1174 - val_loss: 9.4272 - val_mae: 2.3431\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8841 - mae: 2.1165 - val_loss: 8.4862 - val_mae: 2.1906\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8640 - mae: 2.1056 - val_loss: 8.0713 - val_mae: 2.1518\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7110 - mae: 2.0905 - val_loss: 9.2230 - val_mae: 2.2817\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7040 - mae: 2.0854 - val_loss: 8.7597 - val_mae: 2.1949\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5802 - mae: 2.0761 - val_loss: 8.9055 - val_mae: 2.2697\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5742 - mae: 2.0773 - val_loss: 8.6942 - val_mae: 2.2123\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 8.4786 - mae: 2.0527 - val_loss: 8.2804 - val_mae: 2.1611\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5428 - mae: 2.0782 - val_loss: 9.4386 - val_mae: 2.3000\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.4342 - mae: 2.0695 - val_loss: 8.2480 - val_mae: 2.1485\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3107 - mae: 2.0215 - val_loss: 8.4244 - val_mae: 2.1749\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3601 - mae: 2.0631 - val_loss: 9.3720 - val_mae: 2.2879\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1442 - mae: 2.0278 - val_loss: 8.1256 - val_mae: 2.1206\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2932 - mae: 2.0316 - val_loss: 9.2120 - val_mae: 2.2568\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0087 - mae: 2.0030 - val_loss: 8.6148 - val_mae: 2.1853\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0116 - mae: 1.9965 - val_loss: 8.8364 - val_mae: 2.1999\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9355 - mae: 2.0065 - val_loss: 9.0960 - val_mae: 2.2269\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9228 - mae: 1.9952 - val_loss: 8.7444 - val_mae: 2.1845\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8340 - mae: 1.9713 - val_loss: 9.0213 - val_mae: 2.2174\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9354 - mae: 2.0007 - val_loss: 8.2841 - val_mae: 2.1321\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9007 - mae: 1.9716 - val_loss: 9.1922 - val_mae: 2.2484\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7390 - mae: 1.9587 - val_loss: 8.7487 - val_mae: 2.1764\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6360 - mae: 1.9469 - val_loss: 8.5316 - val_mae: 2.1660\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5861 - mae: 1.9373 - val_loss: 8.7806 - val_mae: 2.1978\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5546 - mae: 1.9500 - val_loss: 9.5944 - val_mae: 2.2618\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5103 - mae: 1.9410 - val_loss: 9.1020 - val_mae: 2.2181\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4514 - mae: 1.9225 - val_loss: 8.8771 - val_mae: 2.2006\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.3558 - mae: 1.9137 - val_loss: 8.8348 - val_mae: 2.1943\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.4598 - mae: 1.9631 - val_loss: 9.6046 - val_mae: 2.2447\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3554 - mae: 1.9067 - val_loss: 9.3261 - val_mae: 2.2144\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3811 - mae: 1.9083 - val_loss: 8.9395 - val_mae: 2.1569\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2173 - mae: 1.9072 - val_loss: 10.0801 - val_mae: 2.2876\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3264 - mae: 1.9211 - val_loss: 9.1435 - val_mae: 2.1585\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1842 - mae: 1.9014 - val_loss: 9.1313 - val_mae: 2.2005\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1421 - mae: 1.9162 - val_loss: 9.7473 - val_mae: 2.2466\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0466 - mae: 1.8822 - val_loss: 9.2069 - val_mae: 2.1712\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0642 - mae: 1.8790 - val_loss: 8.5353 - val_mae: 2.1192\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9019 - mae: 1.8830 - val_loss: 10.2708 - val_mae: 2.3086\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9973 - mae: 1.8751 - val_loss: 9.2975 - val_mae: 2.2295\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9327 - mae: 1.8770 - val_loss: 9.1507 - val_mae: 2.1999\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8859 - mae: 1.8704 - val_loss: 9.2942 - val_mae: 2.2018\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8280 - mae: 1.8561 - val_loss: 9.6681 - val_mae: 2.2203\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 6.8166 - mae: 1.8542 - val_loss: 9.5006 - val_mae: 2.1919\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7441 - mae: 1.8366 - val_loss: 9.2471 - val_mae: 2.1294\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7214 - mae: 1.8657 - val_loss: 9.8196 - val_mae: 2.2474\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6479 - mae: 1.8327 - val_loss: 9.0200 - val_mae: 2.1633\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step - loss: 17.9333 - mae: 2.7366\n",
      "Mean squared error on test data:  17.933349609375\n",
      "Mean absolute error on test data:  2.7365949153900146\n"
     ]
    }
   ],
   "source": [
    "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "print('Mean squared error on test data: ', mse_nn)\n",
    "print('Mean absolute error on test data: ', mae_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>MSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>number of layers</th>\n",
       "      <th>neurons_2layer</th>\n",
       "      <th>mae</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 1</td>\n",
       "      <td>17.93335</td>\n",
       "      <td>2.736595</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1.832693</td>\n",
       "      <td>2.163337</td>\n",
       "      <td>6.647884</td>\n",
       "      <td>9.020004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  MSE Test  MAE Test optimizer  number of layers  neurons_2layer  \\\n",
       "0    model 1  17.93335  2.736595      ADAM                 3              64   \n",
       "\n",
       "        mae   val_mae      loss  val_loss  \n",
       "0  1.832693  2.163337  6.647884  9.020004  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame({\n",
    "    'model_name': 'model 1',\n",
    "    'MSE Test': [mse_nn],\n",
    "    'MAE Test': [mae_nn],\n",
    "    'optimizer': ['ADAM'],\n",
    "    'number of layers': [3],\n",
    "    'neurons_2layer': [64], \n",
    "    'mae': [history.history['mae'][-1]],\n",
    "    'val_mae': [history.history['val_mae'][-1]],\n",
    "    'loss': [history.history['loss'][-1]],\n",
    "    'val_loss' : [history.history['val_loss'][-1]]\n",
    "})\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_metrics(modelname, neurons = 64, optimizer = \"ADAM\",  layers = 0):\n",
    "    \"\"\"\n",
    "    В данной функции можно изменять кол-во слоев, оптимизатор,\n",
    "    кол-во нейронов в слоях и сохранять метрики моделей\n",
    "    \"\"\"\n",
    "    global X_train, y_train, X_test, y_test, metrics\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(13, ), activation='relu'))\n",
    "    \n",
    "    for i in range(0, layers):\n",
    "         model.add(Dense(neurons - i * 10, activation='relu')) # i-10 костыль, который уменьшает колво нейронов в последующих слоях\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_split=0.05)\n",
    "    mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
    "    \n",
    "    model_metrics = pd.DataFrame({\n",
    "        'model_name': f'{modelname}',\n",
    "        'MSE Test': [mse_nn] ,\n",
    "        'MAE Test': [mae_nn],\n",
    "        'optimizer': [optimizer],\n",
    "        'number of layers': [2 + layers], \n",
    "        'neurons_2layer': [neurons], \n",
    "        'mae': [history.history['mae'][-1]],\n",
    "        'val_mae': [history.history['val_mae'][-1]],\n",
    "        'loss': [history.history['loss'][-1]],\n",
    "        'val_loss' : [history.history['val_loss'][-1]]\n",
    "    })\n",
    "    \n",
    "    metrics = metrics.append(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение различных моделей и просмотр их метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 567.6324 - mae: 21.9767 - val_loss: 566.2653 - val_mae: 21.9362\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 493.0203 - mae: 20.1709 - val_loss: 483.6541 - val_mae: 20.0419\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 400.4441 - mae: 17.7358 - val_loss: 372.0131 - val_mae: 17.2263\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 282.1037 - mae: 14.5081 - val_loss: 242.1825 - val_mae: 13.4318\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 164.9864 - mae: 10.5698 - val_loss: 121.9858 - val_mae: 9.0300\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 81.7643 - mae: 7.2027 - val_loss: 56.7115 - val_mae: 5.9371\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.8976 - mae: 5.5952 - val_loss: 33.5390 - val_mae: 4.4615\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 38.9513 - mae: 4.6681 - val_loss: 22.9623 - val_mae: 3.8271\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 28.9653 - mae: 3.9576 - val_loss: 19.0088 - val_mae: 3.4383\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 24.3614 - mae: 3.6377 - val_loss: 16.2698 - val_mae: 3.0464\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.4044 - mae: 3.5019 - val_loss: 14.6641 - val_mae: 2.8650\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.6358 - mae: 3.3446 - val_loss: 14.0382 - val_mae: 2.7785\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.4553 - mae: 3.2121 - val_loss: 13.4920 - val_mae: 2.7088\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 18.5233 - mae: 3.1030 - val_loss: 12.8216 - val_mae: 2.6446\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 17.6489 - mae: 3.0573 - val_loss: 12.0182 - val_mae: 2.6053\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.9981 - mae: 3.0031 - val_loss: 11.3257 - val_mae: 2.5274\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.1721 - mae: 2.9241 - val_loss: 10.7615 - val_mae: 2.5183\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.6637 - mae: 2.8870 - val_loss: 10.1511 - val_mae: 2.4648\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.1875 - mae: 2.8532 - val_loss: 9.8864 - val_mae: 2.3689\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.4491 - mae: 2.7767 - val_loss: 9.5269 - val_mae: 2.2834\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.0396 - mae: 2.6882 - val_loss: 9.1054 - val_mae: 2.2456\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.6162 - mae: 2.6587 - val_loss: 8.8821 - val_mae: 2.2666\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.1571 - mae: 2.6424 - val_loss: 8.5511 - val_mae: 2.2603\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.7831 - mae: 2.5750 - val_loss: 8.2576 - val_mae: 2.1975\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.5229 - mae: 2.5321 - val_loss: 7.9819 - val_mae: 2.2031\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 12.1716 - mae: 2.5085 - val_loss: 8.0261 - val_mae: 2.2465\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 11.8939 - mae: 2.4916 - val_loss: 7.9099 - val_mae: 2.2375\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.6800 - mae: 2.4568 - val_loss: 7.7009 - val_mae: 2.2354\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.5100 - mae: 2.4248 - val_loss: 7.4365 - val_mae: 2.2065\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.1529 - mae: 2.4053 - val_loss: 8.0432 - val_mae: 2.3154\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.0428 - mae: 2.4166 - val_loss: 7.7037 - val_mae: 2.2570\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.7864 - mae: 2.3698 - val_loss: 7.4631 - val_mae: 2.2178\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.6680 - mae: 2.3480 - val_loss: 7.4724 - val_mae: 2.2373\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.4934 - mae: 2.3156 - val_loss: 7.3540 - val_mae: 2.2006\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.3229 - mae: 2.2920 - val_loss: 7.5194 - val_mae: 2.2345\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.1113 - mae: 2.2788 - val_loss: 7.4959 - val_mae: 2.2297\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.9978 - mae: 2.2718 - val_loss: 7.4948 - val_mae: 2.2256\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.8768 - mae: 2.2630 - val_loss: 7.6448 - val_mae: 2.2726\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.8253 - mae: 2.2681 - val_loss: 8.1047 - val_mae: 2.3003\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.6422 - mae: 2.2308 - val_loss: 7.4922 - val_mae: 2.2337\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.5914 - mae: 2.2162 - val_loss: 8.2049 - val_mae: 2.3091\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.4781 - mae: 2.2354 - val_loss: 8.1467 - val_mae: 2.2844\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.4840 - mae: 2.1933 - val_loss: 7.6188 - val_mae: 2.2526\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.1413 - mae: 2.1585 - val_loss: 8.4424 - val_mae: 2.3044\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.1927 - mae: 2.1896 - val_loss: 8.1958 - val_mae: 2.2873\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.1669 - mae: 2.1580 - val_loss: 8.0050 - val_mae: 2.2492\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.1370 - mae: 2.1884 - val_loss: 9.1227 - val_mae: 2.3804\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.9172 - mae: 2.1528 - val_loss: 8.4063 - val_mae: 2.2599\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.9365 - mae: 2.1294 - val_loss: 8.4350 - val_mae: 2.2710\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.7390 - mae: 2.1399 - val_loss: 9.9245 - val_mae: 2.4237\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8095 - mae: 2.1266 - val_loss: 8.8680 - val_mae: 2.2799\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5236 - mae: 2.0985 - val_loss: 10.0008 - val_mae: 2.4284\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.6143 - mae: 2.1321 - val_loss: 9.6871 - val_mae: 2.4198\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5035 - mae: 2.0969 - val_loss: 8.6306 - val_mae: 2.2660\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.4090 - mae: 2.0785 - val_loss: 9.8384 - val_mae: 2.3742\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3270 - mae: 2.0729 - val_loss: 9.3053 - val_mae: 2.3379\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2327 - mae: 2.0676 - val_loss: 9.7487 - val_mae: 2.3993\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1565 - mae: 2.0507 - val_loss: 9.9327 - val_mae: 2.4019\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1723 - mae: 2.0481 - val_loss: 9.5057 - val_mae: 2.3259\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0783 - mae: 2.0327 - val_loss: 10.1963 - val_mae: 2.3965\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0248 - mae: 2.0440 - val_loss: 9.8544 - val_mae: 2.3226\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 7.9887 - mae: 2.0307 - val_loss: 10.0904 - val_mae: 2.3655\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0011 - mae: 2.0213 - val_loss: 9.7900 - val_mae: 2.3466\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1675 - mae: 2.0656 - val_loss: 11.3685 - val_mae: 2.5276\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0773 - mae: 2.0234 - val_loss: 9.2754 - val_mae: 2.2710\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8028 - mae: 2.0249 - val_loss: 11.7980 - val_mae: 2.4950\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7653 - mae: 2.0070 - val_loss: 10.6022 - val_mae: 2.3618\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6685 - mae: 1.9827 - val_loss: 10.4461 - val_mae: 2.3525\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7532 - mae: 1.9978 - val_loss: 11.2563 - val_mae: 2.4640\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6383 - mae: 1.9783 - val_loss: 10.1409 - val_mae: 2.3597\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5715 - mae: 1.9726 - val_loss: 10.9760 - val_mae: 2.4391\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4378 - mae: 1.9589 - val_loss: 10.3201 - val_mae: 2.3909\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4506 - mae: 1.9484 - val_loss: 10.5961 - val_mae: 2.3860\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4211 - mae: 1.9675 - val_loss: 11.4472 - val_mae: 2.4801\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5024 - mae: 1.9484 - val_loss: 10.3606 - val_mae: 2.3494\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5492 - mae: 1.9786 - val_loss: 11.4244 - val_mae: 2.4777\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4284 - mae: 1.9612 - val_loss: 10.7643 - val_mae: 2.3463\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2627 - mae: 1.9324 - val_loss: 11.6211 - val_mae: 2.4730\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4433 - mae: 1.9493 - val_loss: 10.1685 - val_mae: 2.2506\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3430 - mae: 1.9473 - val_loss: 12.4016 - val_mae: 2.4818\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1842 - mae: 1.9168 - val_loss: 10.3198 - val_mae: 2.2475\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0847 - mae: 1.9109 - val_loss: 11.5707 - val_mae: 2.4233\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2117 - mae: 1.9424 - val_loss: 12.9841 - val_mae: 2.5440\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1274 - mae: 1.9222 - val_loss: 11.0470 - val_mae: 2.3627\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.0418 - mae: 1.8993 - val_loss: 11.3838 - val_mae: 2.3792\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0379 - mae: 1.9066 - val_loss: 11.0564 - val_mae: 2.3110\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9880 - mae: 1.9079 - val_loss: 11.3011 - val_mae: 2.3452\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9446 - mae: 1.8897 - val_loss: 12.5406 - val_mae: 2.5094\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8886 - mae: 1.8811 - val_loss: 11.0778 - val_mae: 2.3211\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8819 - mae: 1.8981 - val_loss: 12.0280 - val_mae: 2.4043\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0090 - mae: 1.8816 - val_loss: 10.9090 - val_mae: 2.2436\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9042 - mae: 1.8972 - val_loss: 12.7289 - val_mae: 2.4613\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7159 - mae: 1.8590 - val_loss: 10.9189 - val_mae: 2.2324\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7906 - mae: 1.8694 - val_loss: 11.9685 - val_mae: 2.3941\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9045 - mae: 1.8822 - val_loss: 11.2656 - val_mae: 2.2631\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6791 - mae: 1.8490 - val_loss: 12.2060 - val_mae: 2.4037\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5769 - mae: 1.8449 - val_loss: 11.1006 - val_mae: 2.2364\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6822 - mae: 1.8559 - val_loss: 11.3054 - val_mae: 2.2784\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6970 - mae: 1.8731 - val_loss: 11.9053 - val_mae: 2.3587\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5290 - mae: 1.8125 - val_loss: 11.0968 - val_mae: 2.2391\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 17.5544 - mae: 2.6953\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 569.5451 - mae: 22.0226 - val_loss: 565.1500 - val_mae: 21.9094\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 484.7011 - mae: 20.0201 - val_loss: 439.4736 - val_mae: 18.9716\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 331.2219 - mae: 15.9852 - val_loss: 234.7278 - val_mae: 12.8060\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 135.6729 - mae: 9.3274 - val_loss: 66.3859 - val_mae: 6.4468\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 73.5499 - mae: 6.6409 - val_loss: 44.1582 - val_mae: 5.7146\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 42.8320 - mae: 4.8643 - val_loss: 30.8676 - val_mae: 4.7791\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 30.5788 - mae: 4.0170 - val_loss: 22.0987 - val_mae: 4.0426\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 24.3346 - mae: 3.6199 - val_loss: 17.9423 - val_mae: 3.5836\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.1184 - mae: 3.3866 - val_loss: 16.7040 - val_mae: 3.2478\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.8185 - mae: 3.1614 - val_loss: 15.5971 - val_mae: 3.2369\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.5494 - mae: 3.0264 - val_loss: 14.8255 - val_mae: 3.0815\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 16.4181 - mae: 2.9375 - val_loss: 13.6282 - val_mae: 2.9887\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.4558 - mae: 2.8619 - val_loss: 12.7163 - val_mae: 2.8316\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.7623 - mae: 2.7469 - val_loss: 11.6550 - val_mae: 2.7190\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.8414 - mae: 2.6730 - val_loss: 11.0712 - val_mae: 2.6180\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.3537 - mae: 2.6739 - val_loss: 10.5480 - val_mae: 2.5643\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 12.8015 - mae: 2.5702 - val_loss: 9.7037 - val_mae: 2.3751\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.1686 - mae: 2.5260 - val_loss: 9.5331 - val_mae: 2.5265\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.7609 - mae: 2.5070 - val_loss: 8.9771 - val_mae: 2.4265\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.3815 - mae: 2.4327 - val_loss: 8.8531 - val_mae: 2.4115\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.0404 - mae: 2.4040 - val_loss: 8.4813 - val_mae: 2.3316\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.6603 - mae: 2.3569 - val_loss: 8.9778 - val_mae: 2.4577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.4342 - mae: 2.3344 - val_loss: 8.7178 - val_mae: 2.3857\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.2655 - mae: 2.3169 - val_loss: 8.0470 - val_mae: 2.2698\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.0865 - mae: 2.2894 - val_loss: 8.3931 - val_mae: 2.3456\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.7631 - mae: 2.2575 - val_loss: 9.2423 - val_mae: 2.4209\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.5776 - mae: 2.2531 - val_loss: 8.5540 - val_mae: 2.2870\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.5154 - mae: 2.2333 - val_loss: 9.0413 - val_mae: 2.3165\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3011 - mae: 2.1995 - val_loss: 8.6286 - val_mae: 2.2543\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.1038 - mae: 2.1724 - val_loss: 8.8925 - val_mae: 2.2811\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8865 - mae: 2.1409 - val_loss: 8.1823 - val_mae: 2.1983\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8054 - mae: 2.1262 - val_loss: 8.5287 - val_mae: 2.2762\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.6596 - mae: 2.1221 - val_loss: 8.2188 - val_mae: 2.2092\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5230 - mae: 2.0756 - val_loss: 8.5284 - val_mae: 2.2625\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5875 - mae: 2.1490 - val_loss: 8.8329 - val_mae: 2.2268\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2784 - mae: 2.0766 - val_loss: 7.6995 - val_mae: 2.0387\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2255 - mae: 2.0462 - val_loss: 8.4663 - val_mae: 2.1640\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0024 - mae: 2.0226 - val_loss: 9.3633 - val_mae: 2.2925\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9440 - mae: 2.0462 - val_loss: 7.8033 - val_mae: 2.0699\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0304 - mae: 2.0393 - val_loss: 8.6688 - val_mae: 2.2366\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8192 - mae: 2.0060 - val_loss: 7.8644 - val_mae: 2.1072\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6674 - mae: 1.9793 - val_loss: 8.4836 - val_mae: 2.1843\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5422 - mae: 1.9710 - val_loss: 7.8233 - val_mae: 2.0647\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5577 - mae: 1.9797 - val_loss: 8.2991 - val_mae: 2.0986\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3274 - mae: 1.9369 - val_loss: 7.7440 - val_mae: 2.0595\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2597 - mae: 1.9254 - val_loss: 8.7281 - val_mae: 2.2301\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2580 - mae: 1.9290 - val_loss: 7.4206 - val_mae: 2.0133\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0251 - mae: 1.9052 - val_loss: 7.9665 - val_mae: 2.0536\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9575 - mae: 1.9045 - val_loss: 7.6333 - val_mae: 1.9836\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2032 - mae: 1.9001 - val_loss: 9.3325 - val_mae: 2.2677\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1757 - mae: 1.9199 - val_loss: 8.1392 - val_mae: 2.0707\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8543 - mae: 1.8958 - val_loss: 7.3129 - val_mae: 1.9225\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6696 - mae: 1.8609 - val_loss: 8.4562 - val_mae: 2.1089\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6249 - mae: 1.8321 - val_loss: 8.3478 - val_mae: 2.0804\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0061 - mae: 1.9413 - val_loss: 7.1601 - val_mae: 1.8656\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1210 - mae: 1.8999 - val_loss: 8.9505 - val_mae: 2.1057\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8683 - mae: 1.9118 - val_loss: 7.2510 - val_mae: 1.9217\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6370 - mae: 1.8579 - val_loss: 9.1225 - val_mae: 2.1980\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3113 - mae: 1.8038 - val_loss: 6.9528 - val_mae: 1.8846\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3732 - mae: 1.7913 - val_loss: 8.5815 - val_mae: 2.0118\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3438 - mae: 1.8260 - val_loss: 7.9653 - val_mae: 1.9672\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2400 - mae: 1.8013 - val_loss: 9.7075 - val_mae: 2.1731\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1090 - mae: 1.7948 - val_loss: 8.0338 - val_mae: 1.9648\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0544 - mae: 1.7954 - val_loss: 8.3327 - val_mae: 1.9541\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9983 - mae: 1.7661 - val_loss: 7.9629 - val_mae: 1.9167\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9689 - mae: 1.7618 - val_loss: 8.4494 - val_mae: 2.0306\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8060 - mae: 1.7372 - val_loss: 8.2725 - val_mae: 1.9460\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7162 - mae: 1.7203 - val_loss: 8.1565 - val_mae: 1.9307\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6090 - mae: 1.7019 - val_loss: 8.3749 - val_mae: 1.9716\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5538 - mae: 1.6976 - val_loss: 8.2736 - val_mae: 1.9860\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.4676 - mae: 1.6996 - val_loss: 7.4558 - val_mae: 1.8512\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5517 - mae: 1.6686 - val_loss: 8.8397 - val_mae: 2.0575\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6665 - mae: 1.7422 - val_loss: 7.4485 - val_mae: 1.8707\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.3725 - mae: 1.6639 - val_loss: 9.3735 - val_mae: 2.1875\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.4217 - mae: 1.6809 - val_loss: 7.8636 - val_mae: 1.8717\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.3368 - mae: 1.6833 - val_loss: 8.6934 - val_mae: 2.0637\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.2637 - mae: 1.6622 - val_loss: 9.0587 - val_mae: 2.1132\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0238 - mae: 1.6171 - val_loss: 8.3253 - val_mae: 2.0332\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0700 - mae: 1.6358 - val_loss: 9.5125 - val_mae: 2.1946\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9649 - mae: 1.6035 - val_loss: 7.4586 - val_mae: 1.8751\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9141 - mae: 1.5870 - val_loss: 10.6865 - val_mae: 2.4040\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2528 - mae: 1.6573 - val_loss: 7.7054 - val_mae: 1.9141\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.7908 - mae: 1.6020 - val_loss: 9.6514 - val_mae: 2.2123\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8108 - mae: 1.5947 - val_loss: 7.9866 - val_mae: 1.9445\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8640 - mae: 1.5990 - val_loss: 10.2489 - val_mae: 2.2877\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.7866 - mae: 1.5674 - val_loss: 8.3603 - val_mae: 2.0190\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8963 - mae: 1.6087 - val_loss: 10.1587 - val_mae: 2.2601\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5480 - mae: 1.5309 - val_loss: 9.3727 - val_mae: 2.1950\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6653 - mae: 1.5781 - val_loss: 9.8937 - val_mae: 2.2192\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6218 - mae: 1.5621 - val_loss: 7.9269 - val_mae: 1.9497\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5482 - mae: 1.5511 - val_loss: 10.7893 - val_mae: 2.4097\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.4274 - mae: 1.5162 - val_loss: 9.1357 - val_mae: 2.1484\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6422 - mae: 1.5412 - val_loss: 7.6404 - val_mae: 1.9328\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5788 - mae: 1.5647 - val_loss: 11.0816 - val_mae: 2.3487\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.3704 - mae: 1.5039 - val_loss: 9.2383 - val_mae: 2.1430\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2855 - mae: 1.4792 - val_loss: 8.1046 - val_mae: 2.0060\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5506 - mae: 1.5696 - val_loss: 10.8734 - val_mae: 2.4045\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5244 - mae: 1.5150 - val_loss: 8.6431 - val_mae: 2.0316\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1931 - mae: 1.4582 - val_loss: 11.1369 - val_mae: 2.4831\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1431 - mae: 1.4739 - val_loss: 9.7692 - val_mae: 2.1334\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 16.0986 - mae: 2.5926\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 586.6456 - mae: 22.3349 - val_loss: 589.0792 - val_mae: 22.3089\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 497.9682 - mae: 20.0699 - val_loss: 437.8446 - val_mae: 18.5369\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 295.2099 - mae: 14.4867 - val_loss: 155.7038 - val_mae: 9.5066\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 106.4444 - mae: 8.1839 - val_loss: 64.7667 - val_mae: 5.9612\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 49.8216 - mae: 5.2086 - val_loss: 44.5091 - val_mae: 5.3964\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 34.1347 - mae: 4.1685 - val_loss: 20.4732 - val_mae: 3.7942\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.5357 - mae: 3.6354 - val_loss: 17.0572 - val_mae: 3.4947\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.3399 - mae: 3.5143 - val_loss: 13.6482 - val_mae: 2.9977\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.8346 - mae: 3.1832 - val_loss: 13.0422 - val_mae: 2.8617\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.5157 - mae: 3.0454 - val_loss: 12.6356 - val_mae: 2.7748\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.3066 - mae: 2.9189 - val_loss: 11.9721 - val_mae: 2.6987\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.6807 - mae: 2.9470 - val_loss: 11.1153 - val_mae: 2.5671\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.5258 - mae: 2.7982 - val_loss: 10.7445 - val_mae: 2.6811\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.1692 - mae: 2.7801 - val_loss: 10.0705 - val_mae: 2.6205\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.2074 - mae: 2.5892 - val_loss: 10.2638 - val_mae: 2.6771\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.2467 - mae: 2.7194 - val_loss: 10.2544 - val_mae: 2.6351\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.2592 - mae: 2.4851 - val_loss: 10.4167 - val_mae: 2.7133\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.2835 - mae: 2.5918 - val_loss: 10.2650 - val_mae: 2.6451\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.2081 - mae: 2.4150 - val_loss: 10.3586 - val_mae: 2.6245\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.9735 - mae: 2.3377 - val_loss: 10.2688 - val_mae: 2.5981\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.4975 - mae: 2.3395 - val_loss: 11.0177 - val_mae: 2.6633\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.4631 - mae: 2.3121 - val_loss: 9.1419 - val_mae: 2.3859\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.2713 - mae: 2.3013 - val_loss: 11.4834 - val_mae: 2.6630\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.8074 - mae: 2.2353 - val_loss: 9.5787 - val_mae: 2.4365\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.5624 - mae: 2.2191 - val_loss: 10.7904 - val_mae: 2.4839\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.4566 - mae: 2.2156 - val_loss: 10.5284 - val_mae: 2.4995\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.1545 - mae: 2.1912 - val_loss: 11.0659 - val_mae: 2.4890\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8662 - mae: 2.1288 - val_loss: 11.2000 - val_mae: 2.4611\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8467 - mae: 2.1442 - val_loss: 12.4343 - val_mae: 2.5997\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8333 - mae: 2.1768 - val_loss: 10.0096 - val_mae: 2.3189\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.6037 - mae: 2.1125 - val_loss: 12.1469 - val_mae: 2.5420\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2068 - mae: 2.0653 - val_loss: 11.4756 - val_mae: 2.4394\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3803 - mae: 2.1014 - val_loss: 10.4657 - val_mae: 2.3565\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9936 - mae: 2.0266 - val_loss: 13.1636 - val_mae: 2.7487\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0524 - mae: 2.0442 - val_loss: 10.5762 - val_mae: 2.4077\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7087 - mae: 2.0093 - val_loss: 16.3293 - val_mae: 2.9738\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0644 - mae: 2.0467 - val_loss: 14.1228 - val_mae: 2.6435\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5105 - mae: 2.1815 - val_loss: 9.0308 - val_mae: 2.1488\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1219 - mae: 2.0807 - val_loss: 12.1305 - val_mae: 2.5420\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4913 - mae: 2.0005 - val_loss: 11.0550 - val_mae: 2.3579\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4517 - mae: 1.9732 - val_loss: 16.2469 - val_mae: 2.8301\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1035 - mae: 1.8874 - val_loss: 12.2284 - val_mae: 2.4149\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9929 - mae: 1.8787 - val_loss: 11.5197 - val_mae: 2.3140\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7158 - mae: 1.8731 - val_loss: 11.6029 - val_mae: 2.3278\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5951 - mae: 1.8315 - val_loss: 19.1649 - val_mae: 3.2411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8142 - mae: 1.9176 - val_loss: 10.8052 - val_mae: 2.2456\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5802 - mae: 1.8788 - val_loss: 13.3444 - val_mae: 2.4709\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0681 - mae: 1.7741 - val_loss: 11.0092 - val_mae: 2.2590\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1389 - mae: 1.8004 - val_loss: 15.6522 - val_mae: 2.6493\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7924 - mae: 1.7508 - val_loss: 13.0884 - val_mae: 2.4112\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8510 - mae: 1.7786 - val_loss: 11.6615 - val_mae: 2.3031\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6393 - mae: 1.7215 - val_loss: 13.8407 - val_mae: 2.5223\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7106 - mae: 1.7322 - val_loss: 12.7388 - val_mae: 2.3523\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5019 - mae: 1.7132 - val_loss: 13.3380 - val_mae: 2.3933\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5104 - mae: 1.6887 - val_loss: 14.8485 - val_mae: 2.5904\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.1823 - mae: 1.6772 - val_loss: 12.3358 - val_mae: 2.2928\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.3088 - mae: 1.6877 - val_loss: 11.4722 - val_mae: 2.2195\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0748 - mae: 1.6368 - val_loss: 11.6130 - val_mae: 2.1875\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0725 - mae: 1.6476 - val_loss: 10.9879 - val_mae: 2.1514\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9124 - mae: 1.6076 - val_loss: 16.1086 - val_mae: 2.7067\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8994 - mae: 1.6364 - val_loss: 9.7161 - val_mae: 2.1141\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.1076 - mae: 1.6087 - val_loss: 11.7117 - val_mae: 2.1778\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.7085 - mae: 1.5830 - val_loss: 15.1896 - val_mae: 2.6231\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8812 - mae: 1.6353 - val_loss: 9.1186 - val_mae: 2.0363\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9933 - mae: 1.6641 - val_loss: 12.9946 - val_mae: 2.3667\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6976 - mae: 1.5965 - val_loss: 13.3953 - val_mae: 2.4224\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 4.4629 - mae: 1.5666 - val_loss: 11.2546 - val_mae: 2.2097\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 4.2543 - mae: 1.5142 - val_loss: 11.5061 - val_mae: 2.2262\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 4.1504 - mae: 1.4936 - val_loss: 12.3148 - val_mae: 2.3395\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1906 - mae: 1.5048 - val_loss: 13.4429 - val_mae: 2.4783\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2899 - mae: 1.4967 - val_loss: 15.0813 - val_mae: 2.6720\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1802 - mae: 1.5097 - val_loss: 11.8586 - val_mae: 2.2735\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.9561 - mae: 1.4637 - val_loss: 12.6750 - val_mae: 2.3078\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8210 - mae: 1.4542 - val_loss: 7.8200 - val_mae: 2.1078\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2062 - mae: 1.4969 - val_loss: 12.2470 - val_mae: 2.3850\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7529 - mae: 1.4234 - val_loss: 8.0603 - val_mae: 2.0400\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.9179 - mae: 1.4515 - val_loss: 11.6572 - val_mae: 2.2569\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8170 - mae: 1.4406 - val_loss: 11.8796 - val_mae: 2.3448\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7641 - mae: 1.4300 - val_loss: 7.2874 - val_mae: 1.9813\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7735 - mae: 1.4239 - val_loss: 12.7646 - val_mae: 2.5159\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.6815 - mae: 1.4349 - val_loss: 12.5603 - val_mae: 2.4170\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8456 - mae: 1.4708 - val_loss: 13.2544 - val_mae: 2.5326\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2424 - mae: 1.3244 - val_loss: 10.5499 - val_mae: 2.1863\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2255 - mae: 1.3367 - val_loss: 11.0565 - val_mae: 2.2967\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.2804 - mae: 1.3413 - val_loss: 11.0672 - val_mae: 2.3308\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.1447 - mae: 1.3068 - val_loss: 11.0640 - val_mae: 2.3256\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.0774 - mae: 1.2828 - val_loss: 9.3713 - val_mae: 2.1515\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9141 - mae: 1.2331 - val_loss: 11.2235 - val_mae: 2.3516\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8393 - mae: 1.2264 - val_loss: 9.4735 - val_mae: 2.2142\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.7314 - mae: 1.1912 - val_loss: 10.4795 - val_mae: 2.2528\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.7627 - mae: 1.1857 - val_loss: 10.5388 - val_mae: 2.3021\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.8538 - mae: 1.2361 - val_loss: 9.9156 - val_mae: 2.2425\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.7502 - mae: 1.1970 - val_loss: 9.2330 - val_mae: 2.1300\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.8847 - mae: 1.2224 - val_loss: 9.3927 - val_mae: 2.1448\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.9320 - mae: 1.2511 - val_loss: 9.4369 - val_mae: 2.2174\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.8208 - mae: 1.2306 - val_loss: 9.8408 - val_mae: 2.2631\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2.7063 - mae: 1.2024 - val_loss: 12.2292 - val_mae: 2.4402\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.7629 - mae: 1.2521 - val_loss: 7.8047 - val_mae: 2.0206\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.5723 - mae: 1.1570 - val_loss: 7.2911 - val_mae: 2.0346\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2.4674 - mae: 1.1462 - val_loss: 11.0301 - val_mae: 2.4140\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 15.3799 - mae: 2.5198\n"
     ]
    }
   ],
   "source": [
    "save_model_metrics('model 2', 80, layers = 1)\n",
    "save_model_metrics('model 3', layers = 2)\n",
    "save_model_metrics('model 4', 80, layers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 11ms/step - loss: 522.4362 - mae: 20.9879 - val_loss: 485.9427 - val_mae: 20.2278\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 381.5186 - mae: 17.5765 - val_loss: 349.4564 - val_mae: 16.9338\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 252.5113 - mae: 13.8770 - val_loss: 231.5699 - val_mae: 13.3510\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 150.3961 - mae: 10.2142 - val_loss: 132.8848 - val_mae: 9.4932\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 87.2083 - mae: 7.3938 - val_loss: 78.2671 - val_mae: 7.0615\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 57.6430 - mae: 5.8826 - val_loss: 46.3584 - val_mae: 5.3874\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 41.2190 - mae: 4.8882 - val_loss: 31.8385 - val_mae: 4.6809\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 32.4992 - mae: 4.2810 - val_loss: 27.3112 - val_mae: 4.1837\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.5350 - mae: 3.8407 - val_loss: 20.5370 - val_mae: 3.5943\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 24.3518 - mae: 3.6110 - val_loss: 19.1612 - val_mae: 3.3933\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.7622 - mae: 3.3290 - val_loss: 18.0857 - val_mae: 3.6466\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.7588 - mae: 3.3095 - val_loss: 14.7278 - val_mae: 3.0590\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.8003 - mae: 3.1169 - val_loss: 14.1472 - val_mae: 2.8558\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 17.4021 - mae: 2.9479 - val_loss: 12.5634 - val_mae: 2.8158\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.2746 - mae: 2.8951 - val_loss: 11.1502 - val_mae: 2.8024\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.4438 - mae: 2.7691 - val_loss: 10.5344 - val_mae: 2.6562\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.5646 - mae: 2.6562 - val_loss: 9.4252 - val_mae: 2.5762\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.5947 - mae: 2.5671 - val_loss: 9.0851 - val_mae: 2.6336\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.1916 - mae: 2.5654 - val_loss: 8.5909 - val_mae: 2.5557\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.5260 - mae: 2.5268 - val_loss: 8.4852 - val_mae: 2.4730\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.5266 - mae: 2.4806 - val_loss: 6.7681 - val_mae: 2.1471\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.6801 - mae: 2.3766 - val_loss: 6.5749 - val_mae: 2.1655\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.5226 - mae: 2.3727 - val_loss: 6.0481 - val_mae: 1.9933\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.2581 - mae: 2.3457 - val_loss: 6.1371 - val_mae: 2.0898\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.5819 - mae: 2.2893 - val_loss: 5.4620 - val_mae: 1.8547\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.5529 - mae: 2.2597 - val_loss: 6.7325 - val_mae: 2.2169\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.3581 - mae: 2.2570 - val_loss: 5.6294 - val_mae: 2.0108\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.2775 - mae: 2.2489 - val_loss: 5.1937 - val_mae: 1.9215\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.8020 - mae: 2.1836 - val_loss: 8.6310 - val_mae: 2.4834\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.1160 - mae: 2.2460 - val_loss: 5.4752 - val_mae: 2.0655\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.5754 - mae: 2.2198 - val_loss: 5.3982 - val_mae: 1.9108\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.3721 - mae: 2.1463 - val_loss: 6.2904 - val_mae: 2.1778\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.4636 - mae: 2.1941 - val_loss: 5.4771 - val_mae: 1.8211\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.1511 - mae: 2.1193 - val_loss: 5.6043 - val_mae: 2.0665\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.8999 - mae: 2.1110 - val_loss: 5.4980 - val_mae: 1.9806\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8890 - mae: 2.0601 - val_loss: 6.8665 - val_mae: 2.0187\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.0256 - mae: 2.1159 - val_loss: 5.8341 - val_mae: 2.0628\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7999 - mae: 2.0933 - val_loss: 5.3476 - val_mae: 1.7871\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.4812 - mae: 2.0290 - val_loss: 7.7127 - val_mae: 2.2857\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.6152 - mae: 2.0627 - val_loss: 8.3833 - val_mae: 2.2903\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.4174 - mae: 2.0304 - val_loss: 6.6316 - val_mae: 2.0181\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2518 - mae: 2.0057 - val_loss: 7.3433 - val_mae: 2.2219\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.1695 - mae: 2.0226 - val_loss: 6.2725 - val_mae: 1.9531\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0635 - mae: 1.9805 - val_loss: 11.5227 - val_mae: 2.5575\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.0951 - mae: 2.0301 - val_loss: 6.3629 - val_mae: 1.9325\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.7368 - mae: 1.9639 - val_loss: 7.6163 - val_mae: 2.0365\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.7752 - mae: 1.9622 - val_loss: 6.5936 - val_mae: 1.9100\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7023 - mae: 1.9505 - val_loss: 6.2483 - val_mae: 1.8704\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6925 - mae: 1.9505 - val_loss: 9.3891 - val_mae: 2.2360\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.8276 - mae: 2.0027 - val_loss: 6.7131 - val_mae: 1.8644\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.5827 - mae: 1.9554 - val_loss: 7.2516 - val_mae: 2.0106\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.6446 - mae: 1.9156 - val_loss: 7.0289 - val_mae: 2.0243\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4094 - mae: 1.8838 - val_loss: 7.4499 - val_mae: 1.9909\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5010 - mae: 1.9104 - val_loss: 6.6352 - val_mae: 1.9501\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2479 - mae: 1.8815 - val_loss: 8.3392 - val_mae: 2.1947\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3783 - mae: 1.8933 - val_loss: 5.6744 - val_mae: 1.7558\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1691 - mae: 1.8721 - val_loss: 7.2238 - val_mae: 1.9175\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0870 - mae: 1.8853 - val_loss: 6.9367 - val_mae: 1.8547\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1496 - mae: 1.8913 - val_loss: 10.1261 - val_mae: 2.2963\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3877 - mae: 1.9163 - val_loss: 9.1860 - val_mae: 2.2052\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8822 - mae: 1.8424 - val_loss: 8.9384 - val_mae: 2.3013\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0425 - mae: 1.8657 - val_loss: 6.9688 - val_mae: 1.9642\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9214 - mae: 1.8407 - val_loss: 7.4903 - val_mae: 2.0595\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6266 - mae: 1.8019 - val_loss: 10.5854 - val_mae: 2.2716\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0884 - mae: 1.8514 - val_loss: 8.9324 - val_mae: 2.1914\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8382 - mae: 1.8497 - val_loss: 8.6205 - val_mae: 2.1622\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9154 - mae: 1.8456 - val_loss: 7.6164 - val_mae: 2.0389\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7246 - mae: 1.7966 - val_loss: 10.0489 - val_mae: 2.3189\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7253 - mae: 1.8505 - val_loss: 7.7824 - val_mae: 2.0652\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7698 - mae: 1.8423 - val_loss: 7.6565 - val_mae: 2.0314\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4936 - mae: 1.7812 - val_loss: 10.6253 - val_mae: 2.2956\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5534 - mae: 1.8165 - val_loss: 10.1087 - val_mae: 2.2374\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7827 - mae: 1.8729 - val_loss: 8.4835 - val_mae: 1.9801\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4607 - mae: 1.7792 - val_loss: 7.5146 - val_mae: 1.9583\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2294 - mae: 1.7907 - val_loss: 17.2621 - val_mae: 3.0120\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6907 - mae: 1.8272 - val_loss: 9.1176 - val_mae: 2.1197\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4040 - mae: 1.7959 - val_loss: 10.5923 - val_mae: 2.3434\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4972 - mae: 1.8031 - val_loss: 9.3847 - val_mae: 2.1600\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3204 - mae: 1.7821 - val_loss: 6.4890 - val_mae: 2.0624\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2840 - mae: 1.7674 - val_loss: 9.2107 - val_mae: 2.1154\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2706 - mae: 1.7805 - val_loss: 8.1900 - val_mae: 2.1085\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1262 - mae: 1.7484 - val_loss: 8.1544 - val_mae: 2.0827\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1651 - mae: 1.7210 - val_loss: 8.2887 - val_mae: 2.1235\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1807 - mae: 1.7438 - val_loss: 10.8539 - val_mae: 2.3066\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2510 - mae: 1.7897 - val_loss: 8.2724 - val_mae: 2.0550\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0157 - mae: 1.7184 - val_loss: 11.0507 - val_mae: 2.4204\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0750 - mae: 1.7272 - val_loss: 7.9597 - val_mae: 2.1190\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0992 - mae: 1.7688 - val_loss: 11.3146 - val_mae: 2.3288\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1391 - mae: 1.7456 - val_loss: 10.1774 - val_mae: 2.1915\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8711 - mae: 1.6912 - val_loss: 8.4690 - val_mae: 2.1520\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1221 - mae: 1.7500 - val_loss: 8.8921 - val_mae: 2.0968\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8191 - mae: 1.7185 - val_loss: 9.9656 - val_mae: 2.1770\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7850 - mae: 1.7002 - val_loss: 11.1858 - val_mae: 2.3232\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1706 - mae: 1.7460 - val_loss: 8.6084 - val_mae: 2.1830\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.8155 - mae: 1.6825 - val_loss: 9.7833 - val_mae: 2.2323\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6774 - mae: 1.6945 - val_loss: 8.3258 - val_mae: 2.0554\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7164 - mae: 1.6733 - val_loss: 12.2700 - val_mae: 2.3870\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8536 - mae: 1.7517 - val_loss: 12.4513 - val_mae: 2.4048\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5254 - mae: 1.6231 - val_loss: 7.1179 - val_mae: 2.1204\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6593 - mae: 1.6825 - val_loss: 7.7968 - val_mae: 2.1223\n",
      "5/5 [==============================] - 0s 998us/step - loss: 16.8287 - mae: 2.4918\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 525.3400 - mae: 20.9073 - val_loss: 477.0005 - val_mae: 19.8268\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 382.5101 - mae: 17.2378 - val_loss: 325.8940 - val_mae: 15.8480\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 245.5058 - mae: 13.2978 - val_loss: 190.1219 - val_mae: 11.5296\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 136.7774 - mae: 9.5386 - val_loss: 98.4989 - val_mae: 7.8171\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 73.8046 - mae: 6.7484 - val_loss: 52.5071 - val_mae: 5.6530\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 46.5963 - mae: 5.1416 - val_loss: 31.5645 - val_mae: 4.6827\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 33.6499 - mae: 4.3138 - val_loss: 22.1016 - val_mae: 4.0435\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 26.8163 - mae: 3.8010 - val_loss: 17.7838 - val_mae: 3.5715\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.7741 - mae: 3.5270 - val_loss: 17.3276 - val_mae: 3.3666\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.1991 - mae: 3.3440 - val_loss: 14.1652 - val_mae: 3.0315\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.5733 - mae: 3.2222 - val_loss: 14.2638 - val_mae: 3.2415\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.1163 - mae: 3.1172 - val_loss: 12.4458 - val_mae: 2.9043\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.7687 - mae: 2.9659 - val_loss: 11.8972 - val_mae: 2.6837\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.8196 - mae: 2.8301 - val_loss: 11.2563 - val_mae: 2.6856\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.9766 - mae: 2.8094 - val_loss: 10.2442 - val_mae: 2.4676\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.2228 - mae: 2.6734 - val_loss: 9.6317 - val_mae: 2.5405\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.5223 - mae: 2.6329 - val_loss: 9.0129 - val_mae: 2.3591\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.8278 - mae: 2.5864 - val_loss: 8.9621 - val_mae: 2.3077\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.7040 - mae: 2.5290 - val_loss: 8.6037 - val_mae: 2.3527\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.2520 - mae: 2.4947 - val_loss: 8.2846 - val_mae: 2.3033\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.4689 - mae: 2.4115 - val_loss: 9.0226 - val_mae: 2.4525\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.1592 - mae: 2.3797 - val_loss: 8.6874 - val_mae: 2.4983\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 10.9678 - mae: 2.3805 - val_loss: 9.6341 - val_mae: 2.7037\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.4589 - mae: 2.3388 - val_loss: 12.3025 - val_mae: 3.0635\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.2684 - mae: 2.3314 - val_loss: 8.5506 - val_mae: 2.3323\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.0409 - mae: 2.2835 - val_loss: 7.7068 - val_mae: 2.1515\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.1585 - mae: 2.2570 - val_loss: 8.2110 - val_mae: 2.2321\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.6132 - mae: 2.1991 - val_loss: 8.4903 - val_mae: 2.3315\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.9071 - mae: 2.2515 - val_loss: 8.1207 - val_mae: 2.2776\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3442 - mae: 2.1738 - val_loss: 9.7344 - val_mae: 2.4706\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.1983 - mae: 2.1773 - val_loss: 8.8759 - val_mae: 2.3395\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3154 - mae: 2.1873 - val_loss: 8.6718 - val_mae: 2.3419\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.0506 - mae: 2.1394 - val_loss: 8.9402 - val_mae: 2.3656\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.0318 - mae: 2.1110 - val_loss: 10.9916 - val_mae: 2.5528\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7179 - mae: 2.1068 - val_loss: 12.4239 - val_mae: 2.7606\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7550 - mae: 2.1155 - val_loss: 10.1991 - val_mae: 2.5148\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.6814 - mae: 2.0802 - val_loss: 10.1652 - val_mae: 2.4364\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.6827 - mae: 2.1160 - val_loss: 8.5765 - val_mae: 2.1846\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3288 - mae: 2.0696 - val_loss: 9.1779 - val_mae: 2.2667\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5467 - mae: 2.0522 - val_loss: 13.7521 - val_mae: 2.7551\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.3347 - mae: 2.0704 - val_loss: 9.9313 - val_mae: 2.3024\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.0219 - mae: 2.0274 - val_loss: 10.6136 - val_mae: 2.2582\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8039 - mae: 2.0058 - val_loss: 9.7631 - val_mae: 2.3055\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2515 - mae: 2.0657 - val_loss: 11.3495 - val_mae: 2.4818\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8900 - mae: 1.9966 - val_loss: 9.5999 - val_mae: 2.2137\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9634 - mae: 1.9807 - val_loss: 10.4221 - val_mae: 2.3021\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6528 - mae: 1.9720 - val_loss: 9.4477 - val_mae: 2.0944\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9094 - mae: 2.0009 - val_loss: 8.4435 - val_mae: 2.0395\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7418 - mae: 1.9753 - val_loss: 8.6932 - val_mae: 2.0329\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5972 - mae: 1.9546 - val_loss: 9.1643 - val_mae: 2.0884\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5683 - mae: 1.9568 - val_loss: 10.2574 - val_mae: 2.2153\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4660 - mae: 1.9552 - val_loss: 9.9070 - val_mae: 2.2127\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3778 - mae: 1.9275 - val_loss: 11.3550 - val_mae: 2.3011\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6321 - mae: 1.9692 - val_loss: 10.4718 - val_mae: 2.2182\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5658 - mae: 1.9817 - val_loss: 10.3468 - val_mae: 2.2071\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1745 - mae: 1.8814 - val_loss: 8.8515 - val_mae: 1.9911\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2943 - mae: 1.9220 - val_loss: 11.0303 - val_mae: 2.2167\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2993 - mae: 1.9478 - val_loss: 9.6209 - val_mae: 2.0476\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4984 - mae: 1.9533 - val_loss: 10.1196 - val_mae: 2.0686\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1516 - mae: 1.8914 - val_loss: 7.8305 - val_mae: 2.0510\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3799 - mae: 1.9072 - val_loss: 11.3254 - val_mae: 2.2877\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1015 - mae: 1.8676 - val_loss: 11.7092 - val_mae: 2.3253\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8225 - mae: 1.8470 - val_loss: 9.3050 - val_mae: 2.0749\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1608 - mae: 1.9031 - val_loss: 8.7966 - val_mae: 2.0595\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0491 - mae: 1.8924 - val_loss: 9.8795 - val_mae: 2.0761\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0021 - mae: 1.8491 - val_loss: 8.9475 - val_mae: 1.9630\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9194 - mae: 1.8357 - val_loss: 9.9418 - val_mae: 2.0763\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8356 - mae: 1.8320 - val_loss: 9.3767 - val_mae: 1.9925\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6474 - mae: 1.8171 - val_loss: 10.4499 - val_mae: 2.0651\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8170 - mae: 1.8492 - val_loss: 9.3605 - val_mae: 1.9888\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8216 - mae: 1.8671 - val_loss: 8.0855 - val_mae: 2.1698\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7462 - mae: 1.8052 - val_loss: 16.8155 - val_mae: 2.6735\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5301 - mae: 1.8205 - val_loss: 10.5602 - val_mae: 2.1909\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6472 - mae: 1.8245 - val_loss: 7.9958 - val_mae: 1.9644\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6132 - mae: 1.8253 - val_loss: 9.8093 - val_mae: 1.9171\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5946 - mae: 1.8239 - val_loss: 11.0128 - val_mae: 2.0868\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5316 - mae: 1.7973 - val_loss: 15.4411 - val_mae: 2.4438\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5633 - mae: 1.8252 - val_loss: 11.3969 - val_mae: 2.2093\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2200 - mae: 1.7627 - val_loss: 13.3110 - val_mae: 2.2459\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5736 - mae: 1.7934 - val_loss: 12.3689 - val_mae: 2.0877\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4306 - mae: 1.8306 - val_loss: 10.9773 - val_mae: 2.0732\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2382 - mae: 1.7866 - val_loss: 11.5543 - val_mae: 2.0696\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5487 - mae: 1.8303 - val_loss: 12.1043 - val_mae: 2.2158\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4699 - mae: 1.7953 - val_loss: 11.1310 - val_mae: 2.0667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3438 - mae: 1.7740 - val_loss: 13.0963 - val_mae: 2.2225\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1489 - mae: 1.8008 - val_loss: 13.6186 - val_mae: 2.1802\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1012 - mae: 1.7257 - val_loss: 17.3444 - val_mae: 2.5193\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1704 - mae: 1.7790 - val_loss: 13.8460 - val_mae: 2.2494\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2895 - mae: 1.7936 - val_loss: 10.4514 - val_mae: 1.9286\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0057 - mae: 1.7238 - val_loss: 14.1466 - val_mae: 2.2933\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2205 - mae: 1.7682 - val_loss: 11.4297 - val_mae: 1.9916\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7583 - mae: 1.7097 - val_loss: 8.8678 - val_mae: 2.0635\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2554 - mae: 1.7678 - val_loss: 11.7662 - val_mae: 2.0817\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0408 - mae: 1.7448 - val_loss: 8.9494 - val_mae: 1.9490\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8525 - mae: 1.7242 - val_loss: 12.0044 - val_mae: 1.9203\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8888 - mae: 1.7187 - val_loss: 8.6478 - val_mae: 1.9928\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9955 - mae: 1.7384 - val_loss: 10.2879 - val_mae: 1.9421\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9243 - mae: 1.7131 - val_loss: 8.6992 - val_mae: 1.9057\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9356 - mae: 1.6960 - val_loss: 11.4782 - val_mae: 2.0561\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7362 - mae: 1.7110 - val_loss: 10.9056 - val_mae: 1.9584\n",
      "5/5 [==============================] - 0s 997us/step - loss: 18.8581 - mae: 2.7131\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 489.6208 - mae: 19.9803 - val_loss: 380.0612 - val_mae: 17.4748\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 235.5547 - mae: 12.9875 - val_loss: 123.3612 - val_mae: 9.1080\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 72.8851 - mae: 6.6853 - val_loss: 41.8980 - val_mae: 5.2082\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 39.1234 - mae: 4.6786 - val_loss: 23.7467 - val_mae: 3.9885\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.8113 - mae: 3.9207 - val_loss: 17.4130 - val_mae: 3.2705\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23.3663 - mae: 3.4767 - val_loss: 14.5421 - val_mae: 2.9473\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.9947 - mae: 3.2908 - val_loss: 14.2153 - val_mae: 3.3565\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.4824 - mae: 3.1275 - val_loss: 11.1468 - val_mae: 2.6023\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.8161 - mae: 2.9732 - val_loss: 10.4313 - val_mae: 2.4851\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.9378 - mae: 2.8048 - val_loss: 8.8432 - val_mae: 2.4914\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.4167 - mae: 2.7163 - val_loss: 10.9742 - val_mae: 2.9596\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.9408 - mae: 2.7592 - val_loss: 6.6476 - val_mae: 2.1968\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.4322 - mae: 2.5387 - val_loss: 10.6972 - val_mae: 2.9360\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.4453 - mae: 2.5235 - val_loss: 10.2882 - val_mae: 2.7925\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.7929 - mae: 2.4638 - val_loss: 7.8756 - val_mae: 2.5696\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 11.7801 - mae: 2.4914 - val_loss: 7.8790 - val_mae: 2.3771\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 11.1196 - mae: 2.4538 - val_loss: 12.9941 - val_mae: 2.8419\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.3701 - mae: 2.3302 - val_loss: 13.6804 - val_mae: 2.9808\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.6895 - mae: 2.3913 - val_loss: 7.6497 - val_mae: 2.1881\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.2856 - mae: 2.3730 - val_loss: 6.9067 - val_mae: 2.0983\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.7362 - mae: 2.2264 - val_loss: 10.7336 - val_mae: 2.6478\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.7493 - mae: 2.2575 - val_loss: 7.8000 - val_mae: 2.2105\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.1272 - mae: 2.1933 - val_loss: 6.0974 - val_mae: 1.9256\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.9825 - mae: 2.2867 - val_loss: 6.5929 - val_mae: 1.8861\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.9258 - mae: 2.1522 - val_loss: 16.9957 - val_mae: 3.3272\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.8737 - mae: 2.3061 - val_loss: 5.9375 - val_mae: 2.0121\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8252 - mae: 2.1312 - val_loss: 11.1698 - val_mae: 2.6273\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.9820 - mae: 2.1899 - val_loss: 11.0697 - val_mae: 2.4724\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.4121 - mae: 2.1127 - val_loss: 7.0689 - val_mae: 2.0596\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7152 - mae: 2.1145 - val_loss: 8.4753 - val_mae: 2.2118\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3876 - mae: 2.1237 - val_loss: 9.3978 - val_mae: 2.5001\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.3866 - mae: 2.1281 - val_loss: 11.7929 - val_mae: 2.6385\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.4030 - mae: 2.0698 - val_loss: 8.6984 - val_mae: 2.1750\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.4416 - mae: 2.1116 - val_loss: 12.4906 - val_mae: 2.5400\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5376 - mae: 1.9500 - val_loss: 7.1738 - val_mae: 1.9925\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1893 - mae: 2.1056 - val_loss: 8.1031 - val_mae: 2.1403\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2637 - mae: 2.0329 - val_loss: 7.9466 - val_mae: 2.0663\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.5703 - mae: 2.0066 - val_loss: 8.3791 - val_mae: 2.1446\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8055 - mae: 2.0026 - val_loss: 10.5141 - val_mae: 2.5260\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9143 - mae: 1.9908 - val_loss: 12.7359 - val_mae: 2.6041\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8422 - mae: 2.0681 - val_loss: 10.4647 - val_mae: 2.3366\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2993 - mae: 1.9463 - val_loss: 8.1407 - val_mae: 2.2015\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.3634 - mae: 1.9689 - val_loss: 6.3770 - val_mae: 1.9904\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9495 - mae: 2.0598 - val_loss: 6.2884 - val_mae: 2.0712\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 7.4258 - mae: 1.9590 - val_loss: 8.6380 - val_mae: 2.2519\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 4ms/step - loss: 7.0694 - mae: 1.8726 - val_loss: 8.9994 - val_mae: 2.1610\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.6698 - mae: 2.0639 - val_loss: 5.6437 - val_mae: 1.8455\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9297 - mae: 1.9242 - val_loss: 8.6274 - val_mae: 2.3641\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1903 - mae: 1.9785 - val_loss: 15.6891 - val_mae: 3.1559\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8823 - mae: 1.9248 - val_loss: 10.1677 - val_mae: 2.2479\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0031 - mae: 1.8920 - val_loss: 6.8343 - val_mae: 2.0205\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2174 - mae: 1.9580 - val_loss: 18.5897 - val_mae: 3.3412\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2340 - mae: 1.9570 - val_loss: 8.5563 - val_mae: 2.0517\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7558 - mae: 1.8949 - val_loss: 7.0281 - val_mae: 2.0125\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6047 - mae: 1.8298 - val_loss: 7.1557 - val_mae: 1.9698\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7784 - mae: 1.9653 - val_loss: 6.3020 - val_mae: 1.9364\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.6105 - mae: 1.8679 - val_loss: 6.2007 - val_mae: 1.8753\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.7688 - mae: 1.9131 - val_loss: 7.6942 - val_mae: 2.1409\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5572 - mae: 1.8274 - val_loss: 9.8667 - val_mae: 2.3091\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3126 - mae: 1.8097 - val_loss: 9.8500 - val_mae: 2.2628\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3103 - mae: 1.8420 - val_loss: 12.5541 - val_mae: 2.7170\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4103 - mae: 1.8347 - val_loss: 7.6548 - val_mae: 2.0307\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5935 - mae: 1.8564 - val_loss: 8.7003 - val_mae: 2.1590\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9590 - mae: 1.7315 - val_loss: 6.3013 - val_mae: 1.9957\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8575 - mae: 1.9078 - val_loss: 8.4941 - val_mae: 2.0671\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8162 - mae: 1.8856 - val_loss: 10.3898 - val_mae: 2.2940\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0999 - mae: 1.7566 - val_loss: 12.1659 - val_mae: 2.6707\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7161 - mae: 1.7154 - val_loss: 17.7050 - val_mae: 3.2419\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4267 - mae: 1.8812 - val_loss: 8.5621 - val_mae: 2.1474\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8815 - mae: 1.7266 - val_loss: 13.9890 - val_mae: 2.8175\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7583 - mae: 1.7064 - val_loss: 11.2063 - val_mae: 2.4040\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.9528 - mae: 1.7423 - val_loss: 10.5494 - val_mae: 2.3338\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2861 - mae: 1.6766 - val_loss: 9.0346 - val_mae: 2.2019\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8279 - mae: 1.8489 - val_loss: 8.8392 - val_mae: 2.2083\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8284 - mae: 1.7120 - val_loss: 9.2332 - val_mae: 2.2397\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8638 - mae: 1.7702 - val_loss: 6.7585 - val_mae: 1.9587\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 6.0335 - mae: 1.7368 - val_loss: 15.7296 - val_mae: 2.9234\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7796 - mae: 1.7162 - val_loss: 7.0439 - val_mae: 2.0398\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7189 - mae: 1.7033 - val_loss: 6.6873 - val_mae: 2.1154\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8882 - mae: 1.7442 - val_loss: 7.8418 - val_mae: 2.0387\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.4669 - mae: 1.7027 - val_loss: 13.6863 - val_mae: 2.7576\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8211 - mae: 1.8215 - val_loss: 7.3614 - val_mae: 2.1554\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.1133 - mae: 1.6497 - val_loss: 6.6006 - val_mae: 1.9757\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8063 - mae: 1.6022 - val_loss: 11.4902 - val_mae: 2.4756\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2278 - mae: 1.6757 - val_loss: 6.7291 - val_mae: 2.0047\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2618 - mae: 1.7873 - val_loss: 6.8959 - val_mae: 1.9163\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.7545 - mae: 1.5604 - val_loss: 6.9079 - val_mae: 2.0091\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9145 - mae: 1.5479 - val_loss: 20.1616 - val_mae: 3.5194\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2262 - mae: 1.8793 - val_loss: 12.5768 - val_mae: 2.6048\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5994 - mae: 1.7334 - val_loss: 7.4619 - val_mae: 2.0409\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2117 - mae: 1.6563 - val_loss: 6.7571 - val_mae: 2.1752\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0110 - mae: 1.6115 - val_loss: 7.8308 - val_mae: 2.4072\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2353 - mae: 1.6573 - val_loss: 6.9807 - val_mae: 2.1084\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5783 - mae: 1.6997 - val_loss: 10.0599 - val_mae: 2.3114\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.3361 - mae: 1.6879 - val_loss: 9.0878 - val_mae: 2.6489\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8971 - mae: 1.5610 - val_loss: 9.3634 - val_mae: 2.4501\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5371 - mae: 1.6829 - val_loss: 6.7506 - val_mae: 2.0636\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.3988 - mae: 1.5321 - val_loss: 6.4312 - val_mae: 2.1164\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5911 - mae: 1.6678 - val_loss: 8.6950 - val_mae: 2.3405\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.5315 - mae: 1.5196 - val_loss: 15.0426 - val_mae: 2.9089\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 20.0841 - mae: 3.0298\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 12ms/step - loss: 522.9208 - mae: 20.7334 - val_loss: 383.2902 - val_mae: 17.2448\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 194.2807 - mae: 11.3089 - val_loss: 87.5304 - val_mae: 7.0237\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 63.4030 - mae: 6.0148 - val_loss: 29.1990 - val_mae: 4.4685\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 35.4950 - mae: 4.3642 - val_loss: 18.6694 - val_mae: 3.6311\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23.1946 - mae: 3.4947 - val_loss: 11.1845 - val_mae: 2.8286\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.4708 - mae: 3.1938 - val_loss: 11.7688 - val_mae: 2.9239\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 18.1792 - mae: 3.0584 - val_loss: 9.3390 - val_mae: 2.5500\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 15.9674 - mae: 2.8681 - val_loss: 7.5306 - val_mae: 2.1956\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 16.0509 - mae: 2.8616 - val_loss: 6.9524 - val_mae: 2.1090\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.1576 - mae: 2.7523 - val_loss: 12.2539 - val_mae: 3.0567\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 14.0375 - mae: 2.7446 - val_loss: 10.2170 - val_mae: 2.8270\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 13.9194 - mae: 2.7039 - val_loss: 8.8084 - val_mae: 2.4045\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.8565 - mae: 2.4681 - val_loss: 9.0039 - val_mae: 2.4962\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 12.4968 - mae: 2.5546 - val_loss: 7.4643 - val_mae: 2.4149\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.9388 - mae: 2.4051 - val_loss: 10.4470 - val_mae: 2.5663\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 12.7941 - mae: 2.6349 - val_loss: 7.9232 - val_mae: 2.2509\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.7870 - mae: 2.4144 - val_loss: 5.3867 - val_mae: 1.9570\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 11.4568 - mae: 2.4479 - val_loss: 9.9488 - val_mae: 2.4191\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.6696 - mae: 2.2435 - val_loss: 6.1464 - val_mae: 2.0726\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 10.7116 - mae: 2.3946 - val_loss: 22.0419 - val_mae: 3.8285\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.4221 - mae: 2.3040 - val_loss: 5.8331 - val_mae: 1.9157\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.8141 - mae: 2.1130 - val_loss: 8.0734 - val_mae: 2.1753\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 10.6848 - mae: 2.4691 - val_loss: 7.9850 - val_mae: 2.1115\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.4582 - mae: 2.0539 - val_loss: 6.9737 - val_mae: 1.9893\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.4373 - mae: 2.2311 - val_loss: 6.5388 - val_mae: 1.9197\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.3414 - mae: 2.2557 - val_loss: 7.8110 - val_mae: 2.4076\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9.2539 - mae: 2.2374 - val_loss: 8.2886 - val_mae: 2.1352\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.1926 - mae: 2.0507 - val_loss: 16.7074 - val_mae: 3.1675\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.7835 - mae: 2.1781 - val_loss: 12.1589 - val_mae: 2.5544\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.9593 - mae: 2.1092 - val_loss: 12.8502 - val_mae: 2.7455\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.5787 - mae: 2.1744 - val_loss: 10.6681 - val_mae: 2.4134\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2675 - mae: 1.9364 - val_loss: 18.9365 - val_mae: 3.3688\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9591 - mae: 2.1059 - val_loss: 10.6470 - val_mae: 2.4439\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9.4012 - mae: 2.2469 - val_loss: 10.1501 - val_mae: 2.3056\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.9361 - mae: 2.0697 - val_loss: 10.4318 - val_mae: 2.2763\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2222 - mae: 1.9429 - val_loss: 10.6794 - val_mae: 2.4101\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7859 - mae: 2.0435 - val_loss: 15.0577 - val_mae: 2.7735\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.8509 - mae: 1.9775 - val_loss: 9.7820 - val_mae: 2.2599\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4823 - mae: 1.9529 - val_loss: 6.6157 - val_mae: 2.1937\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.8581 - mae: 1.8978 - val_loss: 7.7588 - val_mae: 2.0217\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9645 - mae: 1.9642 - val_loss: 7.4632 - val_mae: 2.0605\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.0491 - mae: 1.9902 - val_loss: 6.7557 - val_mae: 2.1155\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7825 - mae: 2.0654 - val_loss: 7.5126 - val_mae: 1.9628\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.7828 - mae: 2.0830 - val_loss: 19.4682 - val_mae: 3.1740\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7311 - mae: 1.7665 - val_loss: 7.4592 - val_mae: 2.0606\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 8.5226 - mae: 2.1597 - val_loss: 7.3974 - val_mae: 1.9878\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 6.3061 - mae: 1.7916 - val_loss: 8.8074 - val_mae: 2.2654\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5597 - mae: 1.8956 - val_loss: 7.5632 - val_mae: 2.0782\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.2043 - mae: 1.9113 - val_loss: 7.9160 - val_mae: 2.0176\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1804 - mae: 1.8903 - val_loss: 11.8435 - val_mae: 2.3621\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.3568 - mae: 1.8649 - val_loss: 10.8367 - val_mae: 2.0964\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.6584 - mae: 1.7684 - val_loss: 6.2353 - val_mae: 2.0787\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0877 - mae: 1.8254 - val_loss: 21.1870 - val_mae: 3.5328\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8.2094 - mae: 2.1850 - val_loss: 10.9810 - val_mae: 2.8811\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.9095 - mae: 1.7748 - val_loss: 7.6485 - val_mae: 2.1237\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5270 - mae: 1.8839 - val_loss: 9.6954 - val_mae: 2.1587\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4140 - mae: 1.8839 - val_loss: 6.7516 - val_mae: 2.1002\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.9467 - mae: 1.8154 - val_loss: 8.7330 - val_mae: 2.0961\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.1051 - mae: 1.9647 - val_loss: 28.5626 - val_mae: 3.7926\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.9829 - mae: 1.6913 - val_loss: 9.0265 - val_mae: 2.0351\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.5763 - mae: 1.8711 - val_loss: 13.2397 - val_mae: 2.4578\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.1852 - mae: 1.7763 - val_loss: 9.2570 - val_mae: 2.2202\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.4984 - mae: 1.7122 - val_loss: 20.8800 - val_mae: 3.3721\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.9111 - mae: 1.9496 - val_loss: 8.2263 - val_mae: 2.0776\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2973 - mae: 1.8459 - val_loss: 12.3076 - val_mae: 2.3550\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.6516 - mae: 1.5445 - val_loss: 8.2353 - val_mae: 2.3483\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7.4190 - mae: 2.0836 - val_loss: 8.2952 - val_mae: 2.0820\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2153 - mae: 1.6333 - val_loss: 7.2057 - val_mae: 2.1380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.3298 - mae: 1.6956 - val_loss: 9.2631 - val_mae: 2.1329\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.8794 - mae: 1.8159 - val_loss: 11.6361 - val_mae: 2.3133\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0944 - mae: 1.6326 - val_loss: 9.3619 - val_mae: 2.4656\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.3782 - mae: 1.7128 - val_loss: 11.2286 - val_mae: 2.2053\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 6.2138 - mae: 1.8735 - val_loss: 9.3381 - val_mae: 2.0992\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7248 - mae: 1.7431 - val_loss: 10.4954 - val_mae: 2.1467\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 6.5447 - mae: 1.8807 - val_loss: 11.4773 - val_mae: 2.2574\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.1285 - mae: 1.6690 - val_loss: 15.6981 - val_mae: 2.5730\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.1346 - mae: 1.6831 - val_loss: 12.6749 - val_mae: 2.3856\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.7266 - mae: 1.8252 - val_loss: 14.2416 - val_mae: 2.4846\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2412 - mae: 1.7294 - val_loss: 8.5997 - val_mae: 1.9659\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5178 - mae: 1.7194 - val_loss: 7.1598 - val_mae: 1.8510\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.3624 - mae: 1.7247 - val_loss: 6.5918 - val_mae: 1.9451\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5.3815 - mae: 1.7134 - val_loss: 17.2948 - val_mae: 2.9855\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8746 - mae: 1.6475 - val_loss: 8.8787 - val_mae: 1.8963\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.7497 - mae: 1.4071 - val_loss: 18.7365 - val_mae: 3.2289\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5914 - mae: 1.8752 - val_loss: 6.8089 - val_mae: 2.2678\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.5475 - mae: 1.6749 - val_loss: 6.1494 - val_mae: 1.9783\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.8241 - mae: 1.5731 - val_loss: 12.7632 - val_mae: 2.5164\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2636 - mae: 1.4909 - val_loss: 13.2349 - val_mae: 2.5107\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.4114 - mae: 1.8684 - val_loss: 8.4360 - val_mae: 1.9673\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.6475 - mae: 1.4067 - val_loss: 14.6437 - val_mae: 2.6195\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.2466 - mae: 1.8935 - val_loss: 8.6484 - val_mae: 2.1001\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.1991 - mae: 1.5507 - val_loss: 14.9802 - val_mae: 2.7981\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2222 - mae: 1.6652 - val_loss: 8.7737 - val_mae: 2.0479\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.7185 - mae: 1.5668 - val_loss: 7.1000 - val_mae: 1.9711\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6.0200 - mae: 1.8754 - val_loss: 9.2012 - val_mae: 2.1126\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3.8704 - mae: 1.4506 - val_loss: 19.9783 - val_mae: 3.2221\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.2342 - mae: 1.7693 - val_loss: 9.1393 - val_mae: 1.9196\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.2798 - mae: 1.5244 - val_loss: 15.8904 - val_mae: 2.8530\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5.0185 - mae: 1.6362 - val_loss: 9.7066 - val_mae: 2.0101\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4.0225 - mae: 1.4609 - val_loss: 15.2319 - val_mae: 2.3520\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 23.0585 - mae: 3.1379\n"
     ]
    }
   ],
   "source": [
    "save_model_metrics('model 5', 64, \"RMSprop\", layers = 1)\n",
    "save_model_metrics('model 6', 80, \"RMSprop\", layers = 1)\n",
    "save_model_metrics('model 7', 64, \"RMSprop\", layers = 2)\n",
    "save_model_metrics('model 8', 80, \"RMSprop\", layers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 583.8403 - mae: 22.2920 - val_loss: 608.8257 - val_mae: 22.7785\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 563.3076 - mae: 21.8138 - val_loss: 591.5294 - val_mae: 22.4054\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 545.9505 - mae: 21.4012 - val_loss: 574.9228 - val_mae: 22.0365\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 528.6734 - mae: 20.9803 - val_loss: 556.7926 - val_mae: 21.6355\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 510.2811 - mae: 20.5339 - val_loss: 537.3392 - val_mae: 21.1995\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 490.7994 - mae: 20.0543 - val_loss: 517.1071 - val_mae: 20.7337\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 470.7240 - mae: 19.5599 - val_loss: 496.6975 - val_mae: 20.2514\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 450.4280 - mae: 19.0368 - val_loss: 475.4349 - val_mae: 19.7414\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 428.9159 - mae: 18.5013 - val_loss: 453.2149 - val_mae: 19.1950\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 406.7227 - mae: 17.9318 - val_loss: 430.7307 - val_mae: 18.6254\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 384.7120 - mae: 17.3570 - val_loss: 408.3713 - val_mae: 18.0415\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 363.0114 - mae: 16.7928 - val_loss: 385.8066 - val_mae: 17.4370\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 341.4278 - mae: 16.2092 - val_loss: 363.9011 - val_mae: 16.8359\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 320.5494 - mae: 15.6372 - val_loss: 342.6023 - val_mae: 16.2291\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 300.4148 - mae: 15.0532 - val_loss: 322.1008 - val_mae: 15.6216\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 281.1497 - mae: 14.4887 - val_loss: 302.3488 - val_mae: 15.0222\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 262.5708 - mae: 13.9336 - val_loss: 283.1806 - val_mae: 14.4181\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 244.6340 - mae: 13.3518 - val_loss: 265.1356 - val_mae: 13.8563\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 227.8854 - mae: 12.7999 - val_loss: 248.1450 - val_mae: 13.3275\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 212.2519 - mae: 12.2687 - val_loss: 231.8927 - val_mae: 12.7989\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 197.4456 - mae: 11.7473 - val_loss: 216.6981 - val_mae: 12.2819\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 183.7098 - mae: 11.2378 - val_loss: 202.2889 - val_mae: 11.7707\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 170.7391 - mae: 10.7795 - val_loss: 188.7397 - val_mae: 11.2672\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 158.6125 - mae: 10.3316 - val_loss: 176.3778 - val_mae: 10.7851\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 147.6777 - mae: 9.9237 - val_loss: 164.7253 - val_mae: 10.3096\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 137.5309 - mae: 9.5388 - val_loss: 153.8023 - val_mae: 9.8425\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 128.1721 - mae: 9.1803 - val_loss: 143.7230 - val_mae: 9.3872\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 119.7047 - mae: 8.8388 - val_loss: 134.2814 - val_mae: 8.9905\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 111.9435 - mae: 8.5075 - val_loss: 126.0586 - val_mae: 8.6926\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 105.2858 - mae: 8.2109 - val_loss: 118.5788 - val_mae: 8.4170\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 99.2863 - mae: 7.9375 - val_loss: 111.7673 - val_mae: 8.1752\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 93.9057 - mae: 7.7028 - val_loss: 105.2729 - val_mae: 7.9314\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 88.8764 - mae: 7.4586 - val_loss: 99.5758 - val_mae: 7.7047\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 84.5358 - mae: 7.2445 - val_loss: 94.5423 - val_mae: 7.4946\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 80.6860 - mae: 7.0607 - val_loss: 89.9627 - val_mae: 7.2941\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.2286 - mae: 6.8801 - val_loss: 85.7548 - val_mae: 7.1021\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 74.0762 - mae: 6.7141 - val_loss: 81.8884 - val_mae: 6.9164\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 71.2286 - mae: 6.5628 - val_loss: 78.2537 - val_mae: 6.7486\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 68.6186 - mae: 6.4222 - val_loss: 74.8719 - val_mae: 6.5972\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 66.1383 - mae: 6.2835 - val_loss: 71.8441 - val_mae: 6.4536\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.9773 - mae: 6.1620 - val_loss: 69.0902 - val_mae: 6.3187\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 61.9918 - mae: 6.0476 - val_loss: 66.5716 - val_mae: 6.1930\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 60.2047 - mae: 5.9416 - val_loss: 64.2939 - val_mae: 6.0747\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.5137 - mae: 5.8482 - val_loss: 62.0974 - val_mae: 5.9582\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 56.9456 - mae: 5.7588 - val_loss: 59.9409 - val_mae: 5.8406\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 55.4613 - mae: 5.6713 - val_loss: 57.9884 - val_mae: 5.7333\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 54.0635 - mae: 5.5892 - val_loss: 56.1565 - val_mae: 5.6313\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 52.7434 - mae: 5.5123 - val_loss: 54.4669 - val_mae: 5.5485\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 51.5041 - mae: 5.4351 - val_loss: 52.9046 - val_mae: 5.4721\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.3698 - mae: 5.3690 - val_loss: 51.4569 - val_mae: 5.3994\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.3111 - mae: 5.3074 - val_loss: 50.0566 - val_mae: 5.3285\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 48.2801 - mae: 5.2423 - val_loss: 48.7512 - val_mae: 5.2619\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 47.3057 - mae: 5.1842 - val_loss: 47.4548 - val_mae: 5.1962\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 46.3353 - mae: 5.1273 - val_loss: 46.1622 - val_mae: 5.1262\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 45.4239 - mae: 5.0759 - val_loss: 45.0611 - val_mae: 5.0808\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 44.5869 - mae: 5.0251 - val_loss: 43.9970 - val_mae: 5.0383\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 43.7559 - mae: 4.9723 - val_loss: 42.9770 - val_mae: 4.9967\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 43.0097 - mae: 4.9280 - val_loss: 41.9393 - val_mae: 4.9514\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 42.2587 - mae: 4.8813 - val_loss: 40.9986 - val_mae: 4.9112\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 41.5622 - mae: 4.8402 - val_loss: 40.0336 - val_mae: 4.8692\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 40.8558 - mae: 4.7954 - val_loss: 39.1865 - val_mae: 4.8314\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 40.2034 - mae: 4.7540 - val_loss: 38.3739 - val_mae: 4.7986\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 39.6044 - mae: 4.7154 - val_loss: 37.5790 - val_mae: 4.7657\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 38.9891 - mae: 4.6758 - val_loss: 36.8454 - val_mae: 4.7345\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 38.4001 - mae: 4.6400 - val_loss: 36.1079 - val_mae: 4.7028\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 37.8408 - mae: 4.6019 - val_loss: 35.4188 - val_mae: 4.6724\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 37.3168 - mae: 4.5683 - val_loss: 34.6887 - val_mae: 4.6399\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 36.7515 - mae: 4.5334 - val_loss: 34.0651 - val_mae: 4.6112\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 36.2672 - mae: 4.4994 - val_loss: 33.4193 - val_mae: 4.5809\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 35.7947 - mae: 4.4677 - val_loss: 32.8344 - val_mae: 4.5527\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 35.3385 - mae: 4.4371 - val_loss: 32.2798 - val_mae: 4.5253\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 34.8863 - mae: 4.4080 - val_loss: 31.7401 - val_mae: 4.4987\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 34.4473 - mae: 4.3731 - val_loss: 31.1649 - val_mae: 4.4691\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 34.0237 - mae: 4.3482 - val_loss: 30.6444 - val_mae: 4.4423\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 33.6221 - mae: 4.3196 - val_loss: 30.1393 - val_mae: 4.4154\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 33.2329 - mae: 4.2935 - val_loss: 29.6616 - val_mae: 4.3899\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 32.8616 - mae: 4.2668 - val_loss: 29.1986 - val_mae: 4.3642\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 32.5014 - mae: 4.2422 - val_loss: 28.7184 - val_mae: 4.3376\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 32.1506 - mae: 4.2198 - val_loss: 28.2816 - val_mae: 4.3131\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 31.8036 - mae: 4.1923 - val_loss: 27.8040 - val_mae: 4.2866\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 31.4604 - mae: 4.1691 - val_loss: 27.4184 - val_mae: 4.2636\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 31.1379 - mae: 4.1427 - val_loss: 27.0417 - val_mae: 4.2411\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 30.8156 - mae: 4.1203 - val_loss: 26.6661 - val_mae: 4.2185\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 30.5220 - mae: 4.0964 - val_loss: 26.3028 - val_mae: 4.1960\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 30.2238 - mae: 4.0775 - val_loss: 25.9546 - val_mae: 4.1741\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 29.9602 - mae: 4.0543 - val_loss: 25.6198 - val_mae: 4.1529\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 29.6813 - mae: 4.0350 - val_loss: 25.2962 - val_mae: 4.1320\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 29.4212 - mae: 4.0170 - val_loss: 24.9752 - val_mae: 4.1106\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 29.1628 - mae: 3.9951 - val_loss: 24.6244 - val_mae: 4.0869\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 28.9011 - mae: 3.9793 - val_loss: 24.2834 - val_mae: 4.0651\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 28.6640 - mae: 3.9629 - val_loss: 23.9780 - val_mae: 4.0472\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 28.4131 - mae: 3.9441 - val_loss: 23.6997 - val_mae: 4.0298\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 28.2110 - mae: 3.9308 - val_loss: 23.4121 - val_mae: 4.0121\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.9724 - mae: 3.9102 - val_loss: 23.1379 - val_mae: 3.9947\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.7593 - mae: 3.8943 - val_loss: 22.8170 - val_mae: 3.9742\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.5281 - mae: 3.8789 - val_loss: 22.5709 - val_mae: 3.9579\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.3289 - mae: 3.8632 - val_loss: 22.3060 - val_mae: 3.9406\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 27.1339 - mae: 3.8501 - val_loss: 22.0671 - val_mae: 3.9246\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 26.9414 - mae: 3.8343 - val_loss: 21.8403 - val_mae: 3.9087\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 26.7602 - mae: 3.8181 - val_loss: 21.6256 - val_mae: 3.8931\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 27.7624 - mae: 3.6762\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 591.9647 - mae: 22.5081 - val_loss: 615.1146 - val_mae: 22.9539\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 564.2003 - mae: 21.9039 - val_loss: 586.5093 - val_mae: 22.3672\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 532.9449 - mae: 21.2129 - val_loss: 551.3274 - val_mae: 21.6183\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 495.6981 - mae: 20.3412 - val_loss: 509.4274 - val_mae: 20.6891\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.3520 - mae: 19.2921 - val_loss: 462.1691 - val_mae: 19.5982\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 405.3803 - mae: 18.0939 - val_loss: 412.3397 - val_mae: 18.3836\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 356.9978 - mae: 16.7887 - val_loss: 363.2979 - val_mae: 17.1058\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 310.2262 - mae: 15.4524 - val_loss: 315.2209 - val_mae: 15.7547\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 265.0786 - mae: 14.1429 - val_loss: 269.3997 - val_mae: 14.3526\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 223.3898 - mae: 12.8084 - val_loss: 226.3868 - val_mae: 12.9113\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 185.2763 - mae: 11.5086 - val_loss: 188.6133 - val_mae: 11.5046\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 153.2849 - mae: 10.2948 - val_loss: 156.5421 - val_mae: 10.2407\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 127.1351 - mae: 9.2630 - val_loss: 129.5733 - val_mae: 9.2023\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 106.0705 - mae: 8.4169 - val_loss: 108.4523 - val_mae: 8.3325\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 90.2289 - mae: 7.7229 - val_loss: 91.5172 - val_mae: 7.7958\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 78.0764 - mae: 7.1225 - val_loss: 78.6050 - val_mae: 7.3284\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 69.2501 - mae: 6.6529 - val_loss: 68.5102 - val_mae: 6.9035\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 62.5485 - mae: 6.2661 - val_loss: 60.8495 - val_mae: 6.5331\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 57.5788 - mae: 5.9620 - val_loss: 54.4234 - val_mae: 6.1815\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 53.6004 - mae: 5.6976 - val_loss: 49.8507 - val_mae: 5.9041\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 50.4703 - mae: 5.4990 - val_loss: 45.9359 - val_mae: 5.6482\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 47.9190 - mae: 5.3361 - val_loss: 42.8252 - val_mae: 5.4529\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 45.7732 - mae: 5.1890 - val_loss: 40.0887 - val_mae: 5.2730\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 43.8258 - mae: 5.0550 - val_loss: 37.6683 - val_mae: 5.1037\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 42.1187 - mae: 4.9336 - val_loss: 35.3982 - val_mae: 4.9468\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 40.5850 - mae: 4.8278 - val_loss: 33.6345 - val_mae: 4.8423\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1965 - mae: 4.7305 - val_loss: 32.0209 - val_mae: 4.7597\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 37.9570 - mae: 4.6362 - val_loss: 30.6494 - val_mae: 4.6848\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 36.8032 - mae: 4.5544 - val_loss: 29.2741 - val_mae: 4.6066\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 35.7205 - mae: 4.4719 - val_loss: 28.1261 - val_mae: 4.5368\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 34.7843 - mae: 4.4037 - val_loss: 27.0318 - val_mae: 4.4668\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 33.8709 - mae: 4.3339 - val_loss: 26.0667 - val_mae: 4.4016\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 33.0746 - mae: 4.2788 - val_loss: 25.2481 - val_mae: 4.3416\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 32.3063 - mae: 4.2342 - val_loss: 24.4908 - val_mae: 4.2838\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 31.6072 - mae: 4.1851 - val_loss: 23.8021 - val_mae: 4.2276\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 30.9541 - mae: 4.1329 - val_loss: 22.9768 - val_mae: 4.1626\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 30.3376 - mae: 4.0975 - val_loss: 22.3710 - val_mae: 4.1107\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 29.7143 - mae: 4.0527 - val_loss: 21.8824 - val_mae: 4.0640\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 29.1754 - mae: 4.0142 - val_loss: 21.2804 - val_mae: 4.0081\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 28.6291 - mae: 3.9737 - val_loss: 20.7471 - val_mae: 3.9576\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 28.1810 - mae: 3.9457 - val_loss: 20.2060 - val_mae: 3.9039\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.6734 - mae: 3.9032 - val_loss: 19.8397 - val_mae: 3.8633\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 27.2312 - mae: 3.8720 - val_loss: 19.4506 - val_mae: 3.8199\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.8215 - mae: 3.8408 - val_loss: 19.1119 - val_mae: 3.7801\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 26.4508 - mae: 3.8130 - val_loss: 18.7852 - val_mae: 3.7408\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 26.0993 - mae: 3.7809 - val_loss: 18.4913 - val_mae: 3.7036\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 25.7537 - mae: 3.7588 - val_loss: 18.2389 - val_mae: 3.6712\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 25.4478 - mae: 3.7346 - val_loss: 17.8474 - val_mae: 3.6250\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 25.1176 - mae: 3.7142 - val_loss: 17.6075 - val_mae: 3.5914\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 24.8292 - mae: 3.6895 - val_loss: 17.3910 - val_mae: 3.5585\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 24.5279 - mae: 3.6652 - val_loss: 17.1864 - val_mae: 3.5268\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 24.2967 - mae: 3.6428 - val_loss: 16.9145 - val_mae: 3.4960\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 24.0359 - mae: 3.6249 - val_loss: 16.7276 - val_mae: 3.4751\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23.7848 - mae: 3.6024 - val_loss: 16.4927 - val_mae: 3.4561\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23.5454 - mae: 3.5893 - val_loss: 16.3400 - val_mae: 3.4362\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23.3349 - mae: 3.5648 - val_loss: 16.1383 - val_mae: 3.4186\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23.1213 - mae: 3.5494 - val_loss: 15.9869 - val_mae: 3.4001\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.9496 - mae: 3.5313 - val_loss: 15.8112 - val_mae: 3.3825\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.7531 - mae: 3.5162 - val_loss: 15.6260 - val_mae: 3.3658\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.5371 - mae: 3.5054 - val_loss: 15.5131 - val_mae: 3.3504\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.3633 - mae: 3.4882 - val_loss: 15.3889 - val_mae: 3.3348\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.2051 - mae: 3.4770 - val_loss: 15.3213 - val_mae: 3.3177\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 22.0315 - mae: 3.4521 - val_loss: 15.1918 - val_mae: 3.3024\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.8621 - mae: 3.4427 - val_loss: 15.0511 - val_mae: 3.2867\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.7206 - mae: 3.4310 - val_loss: 14.9341 - val_mae: 3.2702\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.5593 - mae: 3.4153 - val_loss: 14.7682 - val_mae: 3.2513\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.4118 - mae: 3.4077 - val_loss: 14.6798 - val_mae: 3.2392\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.2694 - mae: 3.3959 - val_loss: 14.5982 - val_mae: 3.2261\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.1453 - mae: 3.3899 - val_loss: 14.5525 - val_mae: 3.2111\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 21.0126 - mae: 3.3688 - val_loss: 14.4393 - val_mae: 3.1974\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.8781 - mae: 3.3574 - val_loss: 14.3346 - val_mae: 3.1828\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.7654 - mae: 3.3502 - val_loss: 14.2270 - val_mae: 3.1686\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.6313 - mae: 3.3432 - val_loss: 14.1534 - val_mae: 3.1538\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.5449 - mae: 3.3337 - val_loss: 14.0882 - val_mae: 3.1416\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.4147 - mae: 3.3254 - val_loss: 14.0459 - val_mae: 3.1303\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.3101 - mae: 3.3093 - val_loss: 13.9535 - val_mae: 3.1172\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.2180 - mae: 3.3050 - val_loss: 13.8770 - val_mae: 3.1114\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.1134 - mae: 3.2945 - val_loss: 13.8055 - val_mae: 3.1038\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 20.0060 - mae: 3.2877 - val_loss: 13.7763 - val_mae: 3.0883\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.9131 - mae: 3.2765 - val_loss: 13.6868 - val_mae: 3.0796\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.7966 - mae: 3.2643 - val_loss: 13.5592 - val_mae: 3.0661\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 3ms/step - loss: 19.6846 - mae: 3.2595 - val_loss: 13.4871 - val_mae: 3.0572\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.5945 - mae: 3.2520 - val_loss: 13.4175 - val_mae: 3.0512\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 19.5026 - mae: 3.2412 - val_loss: 13.3150 - val_mae: 3.0413\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.4056 - mae: 3.2403 - val_loss: 13.2321 - val_mae: 3.0304\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.3136 - mae: 3.2292 - val_loss: 13.1653 - val_mae: 3.0247\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.2419 - mae: 3.2281 - val_loss: 13.1549 - val_mae: 3.0119\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.1610 - mae: 3.2133 - val_loss: 13.1037 - val_mae: 3.0002\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 19.0602 - mae: 3.2075 - val_loss: 13.0563 - val_mae: 2.9903\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.9782 - mae: 3.1956 - val_loss: 13.0057 - val_mae: 2.9814\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.9090 - mae: 3.1873 - val_loss: 12.9009 - val_mae: 2.9720\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.8027 - mae: 3.1831 - val_loss: 12.8598 - val_mae: 2.9665\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.7273 - mae: 3.1744 - val_loss: 12.8194 - val_mae: 2.9586\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.6718 - mae: 3.1662 - val_loss: 12.7475 - val_mae: 2.9509\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.5904 - mae: 3.1648 - val_loss: 12.7013 - val_mae: 2.9425\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 18.5100 - mae: 3.1555 - val_loss: 12.6558 - val_mae: 2.9343\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.4288 - mae: 3.1441 - val_loss: 12.6022 - val_mae: 2.9267\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.3775 - mae: 3.1381 - val_loss: 12.5419 - val_mae: 2.9231\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.2913 - mae: 3.1366 - val_loss: 12.5146 - val_mae: 2.9170\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 18.2326 - mae: 3.1238 - val_loss: 12.4575 - val_mae: 2.9128\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 30.2874 - mae: 3.5203\n"
     ]
    }
   ],
   "source": [
    "save_model_metrics('model 9', 64, \"Adagrad\", layers = 2)\n",
    "save_model_metrics('model 10', 80, \"Adagrad\", layers = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>MSE Test</th>\n",
       "      <th>MAE Test</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>number of layers</th>\n",
       "      <th>neurons_2layer</th>\n",
       "      <th>mae</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 1</td>\n",
       "      <td>17.933350</td>\n",
       "      <td>2.736595</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1.832693</td>\n",
       "      <td>2.163337</td>\n",
       "      <td>6.647884</td>\n",
       "      <td>9.020004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 2</td>\n",
       "      <td>17.554407</td>\n",
       "      <td>2.695315</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1.812465</td>\n",
       "      <td>2.239071</td>\n",
       "      <td>6.529044</td>\n",
       "      <td>11.096793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 3</td>\n",
       "      <td>16.098577</td>\n",
       "      <td>2.592560</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1.473905</td>\n",
       "      <td>2.133388</td>\n",
       "      <td>4.143065</td>\n",
       "      <td>9.769152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 4</td>\n",
       "      <td>15.379915</td>\n",
       "      <td>2.519833</td>\n",
       "      <td>ADAM</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>1.146205</td>\n",
       "      <td>2.414038</td>\n",
       "      <td>2.467449</td>\n",
       "      <td>11.030061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 5</td>\n",
       "      <td>16.828745</td>\n",
       "      <td>2.491849</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>1.682451</td>\n",
       "      <td>2.122331</td>\n",
       "      <td>5.659335</td>\n",
       "      <td>7.796812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 6</td>\n",
       "      <td>18.858055</td>\n",
       "      <td>2.713082</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>1.711041</td>\n",
       "      <td>1.958431</td>\n",
       "      <td>5.736161</td>\n",
       "      <td>10.905560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 7</td>\n",
       "      <td>20.084101</td>\n",
       "      <td>3.029843</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>1.519633</td>\n",
       "      <td>2.908882</td>\n",
       "      <td>4.531532</td>\n",
       "      <td>15.042629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 8</td>\n",
       "      <td>23.058496</td>\n",
       "      <td>3.137912</td>\n",
       "      <td>RMSprop</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>1.460878</td>\n",
       "      <td>2.352008</td>\n",
       "      <td>4.022519</td>\n",
       "      <td>15.231927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 9</td>\n",
       "      <td>27.762358</td>\n",
       "      <td>3.676168</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>4</td>\n",
       "      <td>64</td>\n",
       "      <td>3.818095</td>\n",
       "      <td>3.893060</td>\n",
       "      <td>26.760159</td>\n",
       "      <td>21.625559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model 10</td>\n",
       "      <td>30.287378</td>\n",
       "      <td>3.520308</td>\n",
       "      <td>Adagrad</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>3.123798</td>\n",
       "      <td>2.912825</td>\n",
       "      <td>18.232573</td>\n",
       "      <td>12.457543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name   MSE Test  MAE Test optimizer  number of layers  neurons_2layer  \\\n",
       "0    model 1  17.933350  2.736595      ADAM                 3              64   \n",
       "0    model 2  17.554407  2.695315      ADAM                 3              80   \n",
       "0    model 3  16.098577  2.592560      ADAM                 4              64   \n",
       "0    model 4  15.379915  2.519833      ADAM                 5              80   \n",
       "0    model 5  16.828745  2.491849   RMSprop                 3              64   \n",
       "0    model 6  18.858055  2.713082   RMSprop                 3              80   \n",
       "0    model 7  20.084101  3.029843   RMSprop                 4              64   \n",
       "0    model 8  23.058496  3.137912   RMSprop                 5              80   \n",
       "0    model 9  27.762358  3.676168   Adagrad                 4              64   \n",
       "0   model 10  30.287378  3.520308   Adagrad                 5              80   \n",
       "\n",
       "        mae   val_mae       loss   val_loss  \n",
       "0  1.832693  2.163337   6.647884   9.020004  \n",
       "0  1.812465  2.239071   6.529044  11.096793  \n",
       "0  1.473905  2.133388   4.143065   9.769152  \n",
       "0  1.146205  2.414038   2.467449  11.030061  \n",
       "0  1.682451  2.122331   5.659335   7.796812  \n",
       "0  1.711041  1.958431   5.736161  10.905560  \n",
       "0  1.519633  2.908882   4.531532  15.042629  \n",
       "0  1.460878  2.352008   4.022519  15.231927  \n",
       "0  3.818095  3.893060  26.760159  21.625559  \n",
       "0  3.123798  2.912825  18.232573  12.457543  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "Из всех обученных моделек наименьшую ошибку на MSE, MAE показывает модель4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
